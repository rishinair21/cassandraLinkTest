{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"RussellSpitzer/spark-cassandra-csv Â· GitHub","alternative_id":5079,"content":"<p>An Example Tool for Using Spark to load a CSV file into Cassandra using spark\nPull Requests and Issues Welcome!</p><pre>Spark CSV Loader 1.0\nUsage: sparkcsvexample [options] filename keyspace table mapping [master] [cassandraIp]\n  filename\n        Filename to read, csv, ex.(file:///temp/file.csv). If no locator uri it provided will look in Hadoop DefaultFS (CFS on DSE)\n  keyspace\n        Keyspace to save to\n  table\n        Table to save to\n  mapping\n        A file containing the names of the Cassandra columns that the csv columns should map to, comma-delimited\n  master\n        Spark Address of Master Node, Default runs `dsetool sparkmaster` to find master\n  cassandraIp\n        Ip Address of Cassandra Server, Default uses Spark Master IP address\n  -m &lt;value&gt; | --maxcores &lt;value&gt;\n        Number of cores to use by this application\n  -x &lt;value&gt; | --executormemory &lt;value&gt;\n        Amount of memory for each executor (JVM Style Strings)\n  -v | --verify\n        Run verification checks after inserting data\n  --help\n        CLI Help\n</pre><p>This tool is designed to work with both standalone Apache Spark and Cassandra Clusters as well as DataStax\nCassandra/Spark Clusters.</p><h2><a href=\"https://github.com/RussellSpitzer/spark-cassandra-csv#requirements\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-requirements\"></a>Requirements</h2><p>(DSE &gt; 4.5.2 or Apache C* &gt; 2.0.5 ) and Spark &gt; 0.9.1</p><h2><a href=\"https://github.com/RussellSpitzer/spark-cassandra-csv#building-the-project\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-building-the-project\"></a>Building the project</h2><p>To build go to the home directory of the project and run</p><pre>./sbt/sbt assembly\n</pre><p>This will produce a fat-jar in <code>target/scala-2.10/spark-csv-assembly-1.0.jar</code>. Which needs to be included in any running\nSpark job. It contains the references to the anonymous functions which Spark will use when running.</p><h2><a href=\"https://github.com/RussellSpitzer/spark-cassandra-csv#creating-the-example-keyspace-and-table\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-creating-the-example-keyspace-and-table\"></a>Creating the Example Keyspace and Table</h2><p>This application assumes that the keyspace and table to be inserted to already exist. To create\nthe table used in the example used below run the following commands in cqlsh.</p><pre>CREATE KEYSPACE ks WITH replication = {\n  'class': 'SimpleStrategy',\n  'replication_factor': '1'\n};\nUSE ks;\nCREATE TABLE tab (\n  key int,\n  data1 int,\n  data2 int,\n  data3 int,\n  PRIMARY KEY ((key))\n)\n</pre><h2><a href=\"https://github.com/RussellSpitzer/spark-cassandra-csv#running-with-datastax-enterprise\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-running-with-datastax-enterprise\"></a>Running with Datastax Enterprise</h2><p>When running on a Datstax Enterprise Cluster with Spark Enabled the app can be run with the included\nrun.sh script. This will include the fat-jar referenced above on the classpath for the dse spark-class call\nand run the application. Running with this method will pickup your spark-env.sh file and correctly place the logs\nin your predefined locations.</p><pre>##example\n./run.sh -m 4 file://`pwd`/exampleCsv ks tab exampleMapping\n</pre><h2><a href=\"https://github.com/RussellSpitzer/spark-cassandra-csv#running-with-apache-cassandra\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-running-with-apache-cassandra\"></a>Running with Apache Cassandra</h2><p>We can run directly from sbt using</p><pre>#Note that here we need to specify the spark master uri and cassandra ip, otherwise\n#the program will try to use DataStax Enterprise to pick up these values\n./sbt/sbt \"run -m 4 file://`pwd`/exampleCsv ks tab exampleMapping spark://127.0.0.1:7077 127.0.0.1\"    \n</pre>"}}]}},"pageContext":{"alternative_id":5079}}