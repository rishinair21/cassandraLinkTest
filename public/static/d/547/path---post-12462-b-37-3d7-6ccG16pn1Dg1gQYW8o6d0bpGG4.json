{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Docker Meet Cassandra. Cassandra Meet Docker.","alternative_id":12462,"content":"<p>After having spent quite a bit of time learning Docker and after hearing strong community interest for the technology even though few have played with it, I figured it’d be be best to share what I’ve learned. Hopefully the knowledge transfer helps newcomers get up and running with Cassandra in a concise, yet deeply informed manner.</p><p>A few years ago I finally started playing with Docker by way of Vagrant. That entire experience was weird. Don’t do it.</p>\n<p>Later Docker Compose was released and all the roadblocks I previously encountered immediately melted away and the power of Docker was made very aware to me. Since then I’ve been like my cat, but instead of “Tuna Tuna Tuna Tuna” it’s more like: “Docker Docker Docker Docker.”</p>\n<p>But the more I spoke about Docker and asked around about Docker, the sadder I became since:</p>\n<ul><li>Few really used Docker.</li>\n  <li>Fewer had even heard of Docker Compose.</li>\n  <li>Everyone was worried about how Docker performance would be in production.</li>\n  <li>Some were waiting for the Mesos and Kubernetes war to play out.\n    <ul><li>Kubernetes won by the way. Read any news around Docker-Kubernetes and AWS-Kubernetes to make your own judgements.</li>\n    </ul></li>\n</ul><p>Within The Last Pickle, I advocate for Docker as best I can. Development project? “Why not use Docker?” Quick test? “<em>cough</em> Docker <em>cough</em>.” Learn everything you can about Grafana, Graphite, and monitoring dashboards you ask? “Okay, Docker it is!”</p>\n<p>About a year later, we’re here and guess what? Now you get to be here with me as well! :tada:</p>\n<h2 id=\"docker-cassandra-bootstrap\">Docker Cassandra Bootstrap</h2>\n<p>In October, <a href=\"https://www.linkedin.com/in/nickmbailey/\">Nick Bailey</a> invited me to present at the local <a href=\"https://www.meetup.com/Austin-Cassandra-Users/\">Austin Cassandra Users Meetup</a> and I figured this was the time to consolidate my recent knowledge and learnings into a simplified project. I figured if I had already spent time on such an intricate project I could save others time and give them a clean environment they could play with, develop on, then move into production.</p>\n<p>That’s how the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap\">docker-cassandra-bootstrap</a> project was born.</p>\n<p>I will stay away from how to run the Docker Cassandra Bootstrap project within this blog post since the instructions are already within the Github project’s <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap\">README.md</a>. Instead, I’ll focus on the individual components, what’s hidden in which nooks, and which stubs are commented out in which crannies for future use and development.</p>\n<h2 id=\"docker-composeyml\">docker-compose.yml</h2>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\">docker-compose.yml</a> is the core building block for any Docker Compose project.</p>\n<h3 id=\"building\">Building</h3>\n<p>What Docker provided was the <code class=\"highlighter-rouge\">Dockerfile</code> which allowed <em>image</em> definitions to run <em>containers</em>. (Note the differentiation that <em>containers</em> are <em>images</em> that are running.) Building an image using Docker was pretty straight forward:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker build .\n</pre></div></div>\n<p>However, building many images would require tagging and additional <code class=\"highlighter-rouge\">docker</code> parameters. And that can get confusing really quickly and definitely isn’t user-friendly.</p>\n<p>Instead, Docker Compose lets you build entire ecosystems of <em>services</em> with a simple command:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose build\n</pre></div></div>\n<p>Now with Docker Compose, you don’t have to keep track of image tagging, <code class=\"highlighter-rouge\">Dockerfile</code> location, or anything else that I gratefully have too little experience with. Instead, <em>images</em> are defined by the <code class=\"highlighter-rouge\">image</code> (from Docker Hub) and <code class=\"highlighter-rouge\">build</code> (from a local <code class=\"highlighter-rouge\">Dockerfile</code>) parameters within a Docker Compose <em>service</em>.</p>\n<h3 id=\"environmental-variables\">Environmental Variables</h3>\n<p>Along with the simplification of image definitions, Docker Compose introduces the <code class=\"highlighter-rouge\">env_file</code> parameter which is a not-quite-bash environmental definition file. It’s slightly different, bash commands will not resolve, you can’t use an envar within another’s definition, and don’t use quotes since those will be considered part of the envar’s value. While these <code class=\"highlighter-rouge\">env_files</code> come with their own limitations, <code class=\"highlighter-rouge\">env_files</code> means I no longer have to have ugly, long, complicated lines like:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker -e KEY=VAL -e KEY2=VAL2 -e WHAT=AMI -e DOING=NOW ...\n</pre></div></div>\n<p>Through the use of <a href=\"https://docs.docker.com/compose/extends/\">multiple <code class=\"highlighter-rouge\">docker-compose.yml</code> files</a>, one can create:</p>\n<ul><li>An <code class=\"highlighter-rouge\">env_file</code> called <code class=\"highlighter-rouge\">settings.env</code> which has all generalized settings.</li>\n  <li>An <code class=\"highlighter-rouge\">env_file</code> called <code class=\"highlighter-rouge\">dev.env</code> which has dev-specific settings.</li>\n  <li>An <code class=\"highlighter-rouge\">env_file</code> called <code class=\"highlighter-rouge\">prod.env</code> which has production-specific settings.</li>\n  <li>An <code class=\"highlighter-rouge\">env_file</code> called <code class=\"highlighter-rouge\">nz.env</code> which will define variables to flip all gifs by 180-degrees to counteract the fact that New Zealanders are upside down.</li>\n</ul><p>At the end of the day, the filenames, segregation, and environmental variable values are for you to use and define within your own ecosystem.</p>\n<p>But that’s getting ahead of ourselves. Just know that you can place whatever environmental variables you want in these files as you create production-specific <code class=\"highlighter-rouge\">env_files</code> which may not get used today, but will be utilized when you move into production.</p>\n<h3 id=\"volumes\">Volumes</h3>\n<p>Within Docker everything within a container that is not stored in <code class=\"highlighter-rouge\">volumes</code> is temporary. This means that if we launch a new container using any given static Docker image, we can manipulate multiple aspects of system configuration, data, file placement, etc, without a concern on changing our stable static environment. If something ever breaks, we simply kill the container, launch a new container based off the same image, and we’re back to our familiar static and stable state. However, if we ever want to persist data, storing this valuable data within Docker <code class=\"highlighter-rouge\">volumes</code> ensures that the data is accessible across container restarts.</p>\n<p>The above statement probably makes up about 90% of my love for Docker (image layer caching probably makes up a majority of the remaining 10%).</p>\n<p>What my declaration of love means is that while a container is running: it is your pet. It does what you ask of it (unless it’s a cat) and it will live with you by your side crunching on the code you fed it. But once your pet has finished processing the provided code, it will vanish into the ether and you can replace it like you would cattle.</p>\n<p>This methodology is a perfect fit for short-lived microservice workers. However, if you want to persist data, or provide configuration files to the worker microservices, you’ll want to use <code class=\"highlighter-rouge\">volumes</code>.</p>\n<p>While you can use <a href=\"https://docs.docker.com/compose/compose-file/#volume-configuration-reference\"><em>named volumes</em></a> to allow Docker to handle the data location for you, not using named volumes will put you in full control of where the data directory will resolve to, can provide performance benefits, and will remove one layer of indirection in case anything should go wrong.</p>\n<p>When people ask about the performance of Docker in production, <code class=\"highlighter-rouge\">volumes</code> are the key component. If your service relies on disk access, use <code class=\"highlighter-rouge\">volumes</code> to ensure a higher level of performance. For all other cases, if there even is a CPU-based performance hit, it should be mild and you can always scale horizontally. The ultimate performance benefit of using Docker is that applications are containerized and are extremely effective at horizontal scaling. Also, consider the time and effort costs to test, deploy, and rollback any production changes when using containers. Although this isn’t essentially performance related, it does increase codebase velocity which may be as valuable as raw performance metrics.</p>\n<h3 id=\"entrypoints\">Entrypoints</h3>\n<p>Back to looking at the <code class=\"highlighter-rouge\">docker-compose.yml</code>, Docker <code class=\"highlighter-rouge\">entrypoints</code> define which program will be executed when a machine begins running. You can think of SSH’s entrypoint as being <code class=\"highlighter-rouge\">bash</code>, or <code class=\"highlighter-rouge\">zsh</code>.</p>\n<p>Under the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\"><code class=\"highlighter-rouge\">cqlsh</code> service</a>, the default <code class=\"highlighter-rouge\">entrypoint</code> is overwritten by <code class=\"highlighter-rouge\">cqlsh cassandra</code>, where <code class=\"highlighter-rouge\">cassandra</code> is the name of the Cassandra Docker Compose service. This means that we want to use the <code class=\"highlighter-rouge\">cassandra:3.11</code> image, but not use the bash script that sets up the <code class=\"highlighter-rouge\">cassandra.yaml</code> and other Cassandra settings. Instead, the service will utilize <code class=\"highlighter-rouge\">cassandra:3.11</code>’s image and start the container with <code class=\"highlighter-rouge\">cqlsh cassandra</code>. This allows the following shorthand command to be run, all within a Docker container, without any local dependencies other than Docker and Docker Compose:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run cqlsh\n</pre></div></div>\n<p>The above command starts up the <code class=\"highlighter-rouge\">cqlsh</code> service, calls the <code class=\"highlighter-rouge\">cqlsh</code> binary, and provides the <code class=\"highlighter-rouge\">cassandra</code> hostname as the contact point.</p>\n<p>The <code class=\"highlighter-rouge\">nodetool</code> service is good example of creating a shorthand command for an otherwise complicated process. Instead of having:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run --entrypoint bash cassandra\n$ nodetool -h cassandra -u cassandraUser -pw cassandraPass status\n</pre></div></div>\n<p>We can simply run:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run nodetool status\n</pre></div></div>\n<p>Any parameters following the service name are appended to the defined <code class=\"highlighter-rouge\">entrypoint</code>’s command and replaces the service’s <code class=\"highlighter-rouge\">command</code> parameter. For the <code class=\"highlighter-rouge\">nodetool</code> service the default <code class=\"highlighter-rouge\">command</code> is <code class=\"highlighter-rouge\">help</code>, but in the above line, the <code class=\"highlighter-rouge\">command</code> that is appended to the <code class=\"highlighter-rouge\">entrypoint</code> is <code class=\"highlighter-rouge\">status</code>.</p>\n<h3 id=\"links\">Links</h3>\n<p>If we have a service that will rely on communication with another service, the way that the <code class=\"highlighter-rouge\">cassandra-reaper</code> service must be in contact with the <code class=\"highlighter-rouge\">cassandra</code> service that Reaper will be monitoring, we can use the <code class=\"highlighter-rouge\">links</code> service parameter to define both the hostname and servicename within this link.</p>\n<p>I like to be both simple and explicit, which is why I use the same name for the hostname and service name like:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>links:\n  - cassandra:cassandra\n</pre></div></div>\n<p>The above line will allow the <code class=\"highlighter-rouge\">cassandra-reaper</code> service’s container to contact the <code class=\"highlighter-rouge\">cassandra</code> service by way of the <code class=\"highlighter-rouge\">cassandra</code> hostname.</p>\n<h3 id=\"ports\">Ports</h3>\n<p>Ports are a way to expose a service’s port to another service, or bind a service’s port to a local port.</p>\n<p>Because the <code class=\"highlighter-rouge\">cassandra-reaper</code> service is meant to be used via its web UI, we bind the service’s <code class=\"highlighter-rouge\">8080</code> and <code class=\"highlighter-rouge\">8081</code> ports from within the service onto the local machine’s <code class=\"highlighter-rouge\">8080</code> and <code class=\"highlighter-rouge\">8081</code> ports using the following lines:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>ports:\n  - \"8080:8080\"\n  - \"8081:8081\"\n</pre></div></div>\n<p>This means if we visit http://localhost:8080/webui/ from our local machine, we’ll be processing code from within a container to service that web request.</p>\n<h3 id=\"restart\">Restart</h3>\n<p>The <code class=\"highlighter-rouge\">restart</code> command is more of a Docker Compose-specific scheduler that dictates what a service should do if the container is abruptly terminated.</p>\n<p>In the case of the <code class=\"highlighter-rouge\">grafana</code> and <code class=\"highlighter-rouge\">logspout</code> services, if Grafana or Logspout ever die, the containers will exit and the <code class=\"highlighter-rouge\">grafana</code> or <code class=\"highlighter-rouge\">logspout</code> services will automatically restart and come back online.</p>\n<p>While this parameter may be ideal for some microservices, it may not be ideal for services that power data stores.</p>\n<h2 id=\"the-cassandra-service\">The <code class=\"highlighter-rouge\">cassandra</code> service</h2>\n<p>The <code class=\"highlighter-rouge\">docker-compose.yml</code> defines the <code class=\"highlighter-rouge\">cassandra</code> service as having a few mounted configuration files.</p>\n<p>The two configuration files that are enabled by default include configurations for:</p>\n<ul><li>collectd.</li>\n  <li>Prometheus JMX exporter.</li>\n</ul><p>The two configuration files that are disabled by default are for:</p>\n<ul><li>The Graphite metrics reporter.</li>\n  <li>The Filebeat log reporter for ELK.</li>\n</ul><h3 id=\"collectd\">collectd</h3>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/config/collectd.cassandra.conf\">cassandra/config/collectd.cassandra.conf</a> configuration file loads a few plugins that TLP has found to be useful for enterprise metric dashboards.</p>\n<p><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/Dockerfile#L62-L74\">A few packages</a> need to be installed for the collectd to be fully installed with the referenced plugins. The service must also be started from within the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/docker-entrypoint.sh#L11\">cassandra/docker-entrypoint.sh</a> or just by using <code class=\"highlighter-rouge\">service collectd start</code> on hardware.</p>\n<p>The metrics that are collected include information on:</p>\n<ul><li>Disk.</li>\n  <li>CPU load.</li>\n  <li>Network traffic.</li>\n  <li>Memory usage.</li>\n  <li>System logs.</li>\n</ul><p>collectd is then configured to write to a Prometheus backend by default. Commented code is included for writing to a Graphite backend.</p>\n<p>For further information on each of the plugins, visit the <a href=\"https://collectd.org/wiki/index.php/Table_of_Plugins\">collectd wiki</a>.</p>\n<h3 id=\"prometheus-jmx-exporter\">Prometheus JMX Exporter</h3>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/config/prometheus.yml\">cassandra/config/prometheus.yml</a> configuration file defines the JMX endpoints that will be collected by the JMX exporter and exposed via a REST API for Prometheus ingestion.</p>\n<p>The following jar needs to be used and referenced within <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/Dockerfile#L78-L85\">cassandra-env.sh</a>:</p>\n<ul><li><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/lib/jmx_prometheus_javaagent-0.9.jar\">cassandra/lib/jmx_prometheus_javaagent-0.9.jar</a></li>\n</ul><p>Only the most important enterprise-centric list of metrics are being collected for Prometheus ingestion.</p>\n<p>The resulting <code class=\"highlighter-rouge\">name</code> formats did not follow the standard Prometheus naming scheme, but instead something between that of the Graphite dot-naming scheme with the use of Prometheus-styled labels when relevant. Do note that Prometheus will automatically convert all dot-separated metrics to underscore-separated metrics since Prometheus does not understand the concept of hierarchical metric keys.</p>\n<h3 id=\"graphite-metrics-reporter\">Graphite Metrics Reporter</h3>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/config/graphite.cassandra.yaml\">cassandra/config/graphite.cassandra.yaml</a> configuration file is included and commented out by default.</p>\n<p>For reporting to work correctly, this file requires the following jars to be placed into <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/Dockerfile#L10-L35\">Cassandra’s lib directory and have Java 8 installed</a>:</p>\n<ul><li><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/lib/metrics-core-3.1.2.jar\">cassandra/lib/metrics-core-3.1.2.jar</a></li>\n  <li><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/lib/metrics-graphite-3.1.2.jar\">cassandra/lib/metrics-graphite-3.1.2.jar</a></li>\n  <li><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/lib/reporter-config-base-3.0.3.jar\">cassandra/lib/reporter-config-base-3.0.3.jar</a></li>\n  <li><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/lib/reporter-config3-3.0.3.jar\">cassandra/lib/reporter-config3-3.0.3.jar</a></li>\n</ul><p>Once properly enabled, the <code class=\"highlighter-rouge\">cassandra</code> service can contact a Graphite host with enterprise-centric metrics. However, we did not include the <code class=\"highlighter-rouge\">graphite</code> service within this project because our experience with Prometheus has been smoother than dealing with Graphite and because Prometheus seems to scale better than Graphite in production environments. As of the most recent Grafana releases, Prometheus has also received plenty of Prometheus-centric features and support as well.</p>\n<h3 id=\"filebeat-log-reporter\">Filebeat Log Reporter</h3>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/config/filebeat.yml\">cassandra/config/filebeat.yml</a> configuration file is set up to contact a pre-existing ELK stack.</p>\n<p>The Filebeat package is required and can be started within a Docker container by referencing the Filebeat service from within <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/Dockerfile#L37-L52\">cassandra-env.sh</a>.</p>\n<p>The Filebeat configuration file is by no means complete (and assume incorrect!), but it does provide a good starting point for learning how to ingest log files into Logstash using Filebeat. Please consider this configuration file as <em>fully experimental</em>.</p>\n<h3 id=\"jmx-authentication\">JMX Authentication</h3>\n<p>Because Reaper for Apache Cassandra will be contacting the JMX port of this <code class=\"highlighter-rouge\">cassandra</code> service we will also need to add <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/Dockerfile#L87-L95\">authentication files for JMX in two locations</a> and set the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/cassandra.env#L15-L17\"><code class=\"highlighter-rouge\">LOCAL_JMX</code> variable to <code class=\"highlighter-rouge\">no</code></a> to expose the JMX port externally while requiring authentication.</p>\n<h2 id=\"the-cqlsh-service\">The <code class=\"highlighter-rouge\">cqlsh</code> Service</h2>\n<p>The <code class=\"highlighter-rouge\">cqlsh</code> service is a helper service that simply uses the <code class=\"highlighter-rouge\">cassandra:3.11</code> image hosted on Docker Hub to provide the cqlsh binary while mounting the local <code class=\"highlighter-rouge\">./cassandra/schema.cql</code> file into the container for simple schema creation and data querying.</p>\n<p>The defined setup allows us to run the following command with ease:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run cqlsh -f /schema.cql\n</pre></div></div>\n<p>The <code class=\"highlighter-rouge\">nodetool</code> service is another helper service that is provided to automatically fill in the host, username, and password parameters.</p>\n<p>By default, it includes the <code class=\"highlighter-rouge\">help</code> <code class=\"highlighter-rouge\">command</code> to provide a list of options for <code class=\"highlighter-rouge\">nodetool</code>. Running the following command will contact the <code class=\"highlighter-rouge\">cassandra</code> node, automatically authenticate, and show a list of options:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run nodetool\n</pre></div></div>\n<p>By including an additional parameter within the command line we will overwrite the <code class=\"highlighter-rouge\">help</code> <code class=\"highlighter-rouge\">command</code> and run that requested command instead, like <code class=\"highlighter-rouge\">status</code>:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose run nodetool status\n</pre></div></div>\n<h2 id=\"the-cassandra-reaper-service\">The <code class=\"highlighter-rouge\">cassandra-reaper</code> Service</h2>\n<p>The <code class=\"highlighter-rouge\">cassandra-reaper</code> service does not use a locally built and customized image, but instead uses an image hosted on <a href=\"https://hub.docker.com/r/thelastpickle/cassandra-reaper/\">Docker Hub</a>. The image that is specifically used is <code class=\"highlighter-rouge\">ab0fff2</code>. However, you can choose to use the <code class=\"highlighter-rouge\">latest</code> release or <code class=\"highlighter-rouge\">master</code> image if you want the bleeding edge version.</p>\n<p>The configuration is all handled via environmental variables for easy Docker consumption within <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra-reaper/cassandra-reaper.env\">cassandra-reaper/cassandra-reaper.env</a>. For a list of all configuration options, see the <a href=\"http://cassandra-reaper.io/docs/configuration/docker_vars/\">Reaper documentation</a>.</p>\n<p>The ports that are exposed onto <code class=\"highlighter-rouge\">localhost</code> are <code class=\"highlighter-rouge\">8080</code> and <code class=\"highlighter-rouge\">8181</code> for the web UI and administration UI, respectively.</p>\n<h2 id=\"the-grafana-service\">The <code class=\"highlighter-rouge\">grafana</code> Service</h2>\n<p>The <code class=\"highlighter-rouge\">grafana</code> service uses the <a href=\"https://hub.docker.com/r/grafana/grafana/\">grafana/grafana</a> image from Docker Hub and is configured using the <code class=\"highlighter-rouge\">grafana/grafana.env</code>. For a list of all configuration options via environmental variables, visit the <a href=\"http://docs.grafana.org/installation/configuration/#using-environment-variables\">Grafana documentation</a>.</p>\n<p>The two scripts included in <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/tree/master/grafana/bin\">grafana/bin/</a> are referenced in the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap#meetup-workflow\">README.md</a> and are used to create data sources that rely on the Prometheus data store and uploads all the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/tree/master/grafana/dashboards\">grafana/dashboard</a> JSON files into Grafana.</p>\n<p>The JSON files were meticulously created for two of our enterprise customer’s production deployments (shared here with permission). They include 7 dashboards that highlight specific Cassandra metrics in a drill-down fashion:</p>\n<ul><li>Overview</li>\n  <li>Read Path</li>\n  <li>Write Path</li>\n  <li>Client Connections</li>\n  <li>Alerts</li>\n  <li>Reaper</li>\n  <li>Big Picture</li>\n</ul><p>At TLP we typically always start off with the Overview dashboard. Depending on our metrics we’ll switch to look at the <a href=\"http://thelastpickle.com/blog/2017/12/05/datadog-tlp-dashboards.html\">Read Path, Write Path, or Client Connection dashboards</a> for further investigation. Do keep in mind that while these dashboards are a work in progress, they do include proper x/y-axis labeling, units, and tooltips/descriptions. The tooltips/descriptions should provide info in the following order, when relevant:</p>\n<ul><li>Description</li>\n  <li>Values</li>\n  <li>False Positives</li>\n  <li>Required Actions</li>\n  <li>Warning</li>\n</ul><p>The text is meant to accompany any alerts that are triggered via the auto-generated Alerts dashboard. This way Slack, PagerDuty, or email alerts contain some context into why the alert was triggered, what most likely culprits may be involved, and how to resolve the alert.</p>\n<p>Do note that while the other dashboards may have triggers set up, only the Alerts dashboard will fire the triggers since all the dashboards make use of Templating Variables for easy Environment, Data Center, and Host selection, which Grafana alerts do not yet support.</p>\n<p>If there are ever any issues around repair, take a look at the Reaper dashboard as well to monitor the Reaper for Apache Cassandra service.</p>\n<p>The Big Picture dashboard provides a 30,000 foot view of the cluster and is nice to reason about, but ultimately provides very little value other than showing the high-level trends of the Cassandra deployment being monitored.</p>\n<h2 id=\"the-logspout-service\">The <code class=\"highlighter-rouge\">logspout</code> Service</h2>\n<p>The <code class=\"highlighter-rouge\">logspout</code> service is a unique service across multiple aspects. While this section will cover some of the special use cases, feel free to skim this section but do try to intake as much information as possible since these sort of use cases will arise in your future docker-compose.yml creations, even if not today.</p>\n<p>At the top of the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\">docker-compose.yml</a> under the <code class=\"highlighter-rouge\">logspout</code> section, we define a <code class=\"highlighter-rouge\">build</code> parameter. This <code class=\"highlighter-rouge\">build</code> parameter references <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/logspout/Dockerfile\">logspout/Dockerfile</a> which has no real information since the <code class=\"highlighter-rouge\">FROM</code> image that our local image refers to uses a few <code class=\"highlighter-rouge\">ONBUILD</code> commands. These commands are defined in the <a href=\"https://github.com/gliderlabs/logspout/blob/master/Dockerfile#L9-L11\">parent image</a> and make use of <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/logspout/modules.go\">logspout/modules.go</a>. Our custom logspout/modules.go installs the required Logstash dependencies for use with pre-existing Logstash deployments.</p>\n<p>While <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/logspout/build.sh\">logspout/build.sh</a> was not required to be duplicated since the parent image already had the file pre-baked, I did so for safekeeping.</p>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/logspout/logspout.env\">logspout/logspout.env</a> file includes a few commented out settings I felt were interesting to look at if I were to experiement with Logstash in the future. These might be a good starting point for further investigation.</p>\n<p>The <code class=\"highlighter-rouge\">logspout</code> service also uses the <code class=\"highlighter-rouge\">restart: always</code> setting to ensure that any possible issues with the log redirection service will automatically be resolved by restarting the service immediately after failure.</p>\n<p>Within the <code class=\"highlighter-rouge\">logspout</code> service, we are redirecting the container’s port <code class=\"highlighter-rouge\">80</code> to our localhost’s port <code class=\"highlighter-rouge\">8000</code>. This allows us to <code class=\"highlighter-rouge\">curl http://localhost:8000/logs</code> from our local machine and grab the logs that the container was displaying on its own REST API under port <code class=\"highlighter-rouge\">80</code>.</p>\n<p>In order for any of the <code class=\"highlighter-rouge\">logspout</code> container magic to work, we need to bind our localhost’s <code class=\"highlighter-rouge\">/var/run/docker.sock</code> into the container as a read-only mount. Even though the mount is read-only, there are still security concerns for doing such an operation. Since this line is still required for allowing this logging redirection to occur, I did include two links to further clarify the security risks involved with including this container within production environments:</p>\n<ul><li>https://raesene.github.io/blog/2016/03/06/The-Dangers-Of-Docker.sock/</li>\n  <li>http://stackoverflow.com/questions/40844197</li>\n</ul><p>Perhaps in the future the Docker/Moby team will provide a more secure workaround.</p>\n<p>The last line that has not been mentioned is the <code class=\"highlighter-rouge\">command</code> option which is commented out by default within the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\">docker-compose.yml</a>. By uncommenting the <code class=\"highlighter-rouge\">command</code> option, we stop using the default <code class=\"highlighter-rouge\">command</code> provided in the parent Dockerfile which exposes the logs via an REST API and we begin to send our logs to the <a href=\"https://papertrailapp.com\">PaperTrail</a> website which provides 100 MB/month of hosted logs for free.</p>\n<p>In order to isolate checked-in code from each developer’s <code class=\"highlighter-rouge\">$PAPERTRAIL_PORT</code>, each developer must locally create a copy of <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/.env.template\">.env.template</a> within their project’s directory under the filename <code class=\"highlighter-rouge\">.env</code>. Within this <code class=\"highlighter-rouge\">.env</code> file we can define environmental variables that will be used by <code class=\"highlighter-rouge\">docker-compose.yml</code>. Once you have an account for PaperTrail, set <code class=\"highlighter-rouge\">PAPERTRAIL_PORT</code> to the port assigned by PaperTrail to begin seeing your logs within <a href=\"https://papertrailapp.com\">PaperTrail.com</a>. And since <code class=\"highlighter-rouge\">.env</code> is setup to be ignored via <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/.gitignore\">.gitignore</a> we do not have to worry about sending multiple developer’s logs to the same location.</p>\n<h2 id=\"the-prometheus-service\">The <code class=\"highlighter-rouge\">prometheus</code> Service</h2>\n<p>The <code class=\"highlighter-rouge\">prometheus</code> service is one of the simpler services within this Docker Compose environment.</p>\n<p>The <code class=\"highlighter-rouge\">prometheus</code> service:</p>\n<ul><li>Uses a <a href=\"https://hub.docker.com/r/prom/prometheus/\">Docker Hub image</a>.</li>\n  <li>Will require access to both the <code class=\"highlighter-rouge\">cassandra</code> and <code class=\"highlighter-rouge\">cassandra-reaper</code> services to monitor their processes.</li>\n  <li>Will expose the container’s port <code class=\"highlighter-rouge\">9090</code> onto localhost’s port <code class=\"highlighter-rouge\">9090</code>.</li>\n  <li>Will persist all data within the container’s <code class=\"highlighter-rouge\">/prometheus</code> directory onto our local <code class=\"highlighter-rouge\">./data/prometheus</code> directory.</li>\n  <li>Will configure the container using a locally-stored copy of the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/prometheus/config/prometheus.yml\">prometheus.yml</a>.</li>\n</ul><p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/prometheus/config/prometheus.yml\">prometheus.yml</a> defines which REST endpoints Prometheus will consume to gather metrics from as well as a few other documented configurations. Prometheus will collect metrics from the following services:</p>\n<ul><li>Prometheus.</li>\n  <li>Cassandra.\n    <ul><li>Cassandra internal metrics.</li>\n      <li>collectd metrics.</li>\n    </ul></li>\n  <li>Reaper for Apache Cassandra.</li>\n</ul><h2 id=\"the-pickle-factory-sample-write-application-service\">The <code class=\"highlighter-rouge\">pickle-factory</code> Sample Write Application Service</h2>\n<p>The <code class=\"highlighter-rouge\">pickle-factory</code>, which is a misnomer and should be “pickle-farm” in hindsight, is a sample application that shows an ideal write pattern.</p>\n<p>For production and development purposes, the <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/pickle-factory/Dockerfile\">pickle-factory/Dockerfile</a> uses the line <code class=\"highlighter-rouge\">COPY . .</code> to copy all of the “microservices” code into the Docker image. The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\">docker-compose.yml</a> uses the <code class=\"highlighter-rouge\">volume</code> key to overwrite any pre-baked code to allow for a simpler development workflow.</p>\n<p>The ideal development to production workflow would be to modify the <code class=\"highlighter-rouge\">pickle-factory/factory.py</code> file directly and have each saved copy refreshed within the running container. Once all changes were tested and committed to <code class=\"highlighter-rouge\">master</code>, a continuous integration (CI) job will build the new Docker images and push those images to Docker Hub for both development and production consumption. The next developer to modify <code class=\"highlighter-rouge\">pickle-factory/factory.py</code> will grab the latest image but use their local copy of <code class=\"highlighter-rouge\">pickle-factory/factory.py</code>. The next time that the production image gets updated it will include the latest copy of <code class=\"highlighter-rouge\">pickle-factory/factory.py</code>, as found in master, directly in the Docker image.</p>\n<p>Included in the Dockerfile is commented out code for installing <code class=\"highlighter-rouge\">gosu</code>, a <code class=\"highlighter-rouge\">sudo</code> replacement for Docker written in Go. <code class=\"highlighter-rouge\">gosu</code> allows the main user to spawn another thread under a non-root user to better contain attackers. Theoretically, if an attacker gains access into the <code class=\"highlighter-rouge\">pickle-factory</code> container, they would do so under a non-privileged user and not be able to potentially breakout of the container into the Docker internals and out onto the host machine. Practically, <code class=\"highlighter-rouge\">gosu</code> limits the possible attack surface on a Docker container. To fully use the provided functionality of <code class=\"highlighter-rouge\">gosu</code>, <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/pickle-factory/docker-entrypoint.sh\">pickle-factory/docker-entrypoint.sh</a> needs to be modified as well.</p>\n<p>The <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/pickle-factory/factory.py\">pickle-factory/factory.py</a> makes a few important design decisions:</p>\n<ul><li>Grabs configurations from environmental variables instead of configuration files for easier Docker-first configurations.</li>\n  <li>The <code class=\"highlighter-rouge\">Cluster()</code> object uses the <code class=\"highlighter-rouge\">DCAwareRoundRobinPolicy</code> in preparation for multiple data centers.</li>\n  <li>The C-based <code class=\"highlighter-rouge\">LibevConnection</code> event loop provider is used since it’s more performant than the Python-native default event loop provider.</li>\n  <li>All statements are prepared in advance to minimize request payload sizes.\n    <ul><li>In the background, the Cassandra nodes will send the statements around to each node in the cluster.</li>\n      <li>The statements will be indexed via a simple integer.</li>\n      <li>All subsequent requests will map the simple integer to the pre-parsed CQL statement.</li>\n    </ul></li>\n  <li>Employee records are generated and written asynchronously instead of synchronously in an effort to improve throughput.</li>\n  <li>Workforce data is denormalized and written asynchronously with a max-buffer to ensure we don’t overload Cassandra with too many in-flight requests.</li>\n  <li>If any requests did not complete successfully the <code class=\"highlighter-rouge\">future.result()</code> call will throw the matching exception.</li>\n</ul><h2 id=\"the-pickle-shop-sample-read-application-service\">The <code class=\"highlighter-rouge\">pickle-shop</code> Sample Read Application Service</h2>\n<p>Much like the <code class=\"highlighter-rouge\">pickle-factory</code> microservice, the <code class=\"highlighter-rouge\">pickle-shop</code> service follows a similar workflow. However, the <code class=\"highlighter-rouge\">pickle-shop</code> service definition within <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/docker-compose.yml\">docker-compose.yml</a> will not overwrite the application code within <code class=\"highlighter-rouge\">/usr/src/app</code> and instead require a rebuilding the local image by using:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>docker-compose build\n</pre></div></div>\n<p>This workflow was chosen as a way to differentiate between a development workflow (<code class=\"highlighter-rouge\">pickle-factory</code>) and a production workflow (<code class=\"highlighter-rouge\">pickle-shop</code>). For production images, all code should ideally be baked into the Docker image and shipped without any external dependencies such as a codebase dependency.</p>\n<p><a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/pickle-shop/shop.py\">pickle-shop/shop.py</a> follows the same overall flow as <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/pickle-factory/factory.py\">pickle-factory/factory.py</a>. After preparing the statements, the read-heavy “microservice” completes the following actions:</p>\n<ul><li>Performs a synchronous read request to grab all the employee IDs.</li>\n  <li>10 asynchronous read queries are performed for 10 employees.</li>\n  <li>We then process all results at the roughly the same time.</li>\n</ul><p>If using a non-asynchronous driver, one would probably follow the alternate workflow:</p>\n<ul><li>Perform 1 synchronous read query for 1 of 10 employees.</li>\n  <li>Process the results of the employee query.</li>\n  <li>Repeat.</li>\n</ul><p>However, following the synchronous workflow will take roughly:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>O(N), where N is the number of employees waiting to be processed\n</pre></div></div>\n<p>Following the asynchronous workflow we will roughly take:</p>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre>O(max(N)), where max(N) is the maximum amount of time an employee query will take.\n</pre></div></div>\n<p>Simplified, the asynchronous workflow will roughly take:</p>\n<p>At the end of this series of information, we have covered:</p>\n<ul><li>Docker</li>\n  <li>Docker Compose</li>\n  <li>A few docker-compose.yml settings.</li>\n  <li>Dockerized Cassandra.</li>\n  <li>Helper Docker Compose services.</li>\n  <li>Dockerized Reaper for Apache Cassandra.</li>\n  <li>Dockerized Grafana.</li>\n  <li>Logspout for Docker-driven external logging.</li>\n  <li>Dockerized Prometheus.</li>\n  <li>A sample write-heavy asynchronous application using Cassandra.</li>\n  <li>A sample read-heavy asynchronous application using Cassandra.</li>\n</ul><p>TLP’s hope is that the above documentation and <a href=\"https://github.com/thelastpickle/docker-cassandra-bootstrap\">minimal Docker Compose ecosystem</a> will provide a starting point for future community Proof of Concepts utilizing Apache Cassandra. With this project, each developer can create, maintain, and develop within their own local environment without any external overhead other than Docker and Docker Compose.</p>\n<p>Once the POC has reached a place of stability, simply adding the project to a Continuous Integration workflow to publish tested images will allow for proper Release Management. After that point, the responsibility typically falls onto the DevOps team to grab the latest Docker image, replace any previously existing Docker containers, and launch the new Docker image. This would all occur without any complicated hand off consisting of dependencies, configuration files (since we’re using environmental variables), and OS-specific requirements.</p>\n<p>Hopefully you will find Docker Compose to be as powerful as I’ve found it to be! Best of luck in cranking out the new POC you’ve been itching to create!</p>"}}]}},"pageContext":{"alternative_id":12462}}