{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Cassandra Hits One Million Writes Per Second on Google Compute Engine","alternative_id":12076,"content":"<div class=\"post-content\" itemprop=\"articleBody\">\n\n<noscript><div>\nGoogle is <a href=\"http://research.google.com/pubs/pub35290.html\">known for creating scalable high performance systems</a>. In a recent blog post, we demonstrated how Google Cloud Platform can rapidly provision and scale networking load to handle <a href=\"http://googlecloudplatform.blogspot.com/2013/11/compute-engine-load-balancing-hits-1-million-requests-per-second.html\">one million requests per second</a>. A fast front end without a fast backend has limited use, so we decided to demonstrate a backend serving infrastructure that could handle the same load. We looked at popular open source building blocks for cloud applications and choose <a href=\"http://cassandra.apache.org/\">Cassandra</a>, a NoSQL database designed for scale and simplicity.<p>Using 330 <a href=\"https://cloud.google.com/products/compute-engine\">Google Compute Engin</a>e virtual machines, 300 1TB Persistent Disk volumes, Debian Linux, and Datastax Cassandra 2.2, we were able to construct a setup that can:<br /></p><ul><li>sustain one million writes per second to Cassandra with a median latency of 10.3 ms and 95% completing under 23 ms</li>\n<li>sustain a loss of ⅓ of the instances and volumes and still maintain the 1 million writes per second (though with higher latency)</li>\n<li>scale up and down linearly so that the configuration described can be used to create a cost effective solution</li>\n<li>go from nothing in existence to a fully configured and deployed instances hitting 1 million writes per second took just 70 minutes. A configured environment can achieve the same throughput in 20 minutes.</li>\n</ul><ul>\n        <a href=\"http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/dml_config_consistency_c.html\">Cassandra Quorum commit</a>                                                      \n                                            \n<a href=\"https://3.bp.blogspot.com/-X7wn0kCzCx4/UypsTp0ms3I/AAAAAAAAAcQ/BymsEROARgs/s3200/diagram.png\"><img border=\"0\" height=\"396\" src=\"https://3.bp.blogspot.com/-X7wn0kCzCx4/UypsTp0ms3I/AAAAAAAAAcQ/BymsEROARgs/s3200/diagram.png\" width=\"640\" alt=\"image\" /></a></ul></div>\n<br /><div>\nYou can find the instructions on how to reproduce the results by following the </div><a href=\"https://gist.github.com/ivansmf/6ec2197b69d1b7b26153\">setup instructions</a><div>.</div><p><b>Results</b><br />\nWith 15,000 concurrent clients Cassandra was able to maintain 10.5ms median latency (8.3ms with 12,000 clients), and 95th latency percentile at 23ms. Here is how the solution scales as the number of concurrent clients grows:<br /><img alt=\"Cassandra Blog Post - latencies and throughput (3).png\" height=\"300px;\" src=\"https://lh5.googleusercontent.com/OmMHhyxMJDH_ye7RbhDuCthdymaBS4QgUFASVNSPVD6kXKc3mxGAOHqUdN28BGs0cJDtFEkYcZLfRHNlVEBEVDShDtpTloZISjBqrVVpc9Ta7VdLskrPQliHCftBFw\" width=\"624px;\" /><br />\nBelow we show a graph of the throughput versus 95th percentile latency which quickly achieves very good response times after Cassandra initializes its internal state, and Java warms up its heap and memory mapped files table. This test was run longer than the minimal time required to hit over 1M writes per second in order to show the sustained throughput:<br /><img alt=\"Cassandra Blog Post - Latency and Throughput superimposed.png\" height=\"301px;\" src=\"https://lh4.googleusercontent.com/unIDk9_mA2E9IIdcEqVgZoNvkJ_SBeoirC8ntNe7DCFWBOTQ0N0r-ASV2qcumLL6KYGBXwa1lUfxcnhMlooYRL18r_UUvOYYgT7BbwVJWuyRIPFaWmOZpXYoYK5TMg\" width=\"624px;\" /><br />\nIn addition to looking at top end performance we also looked at resiliency. We removed ⅓ of the cluster nodes and it remained functional and serving more than 1M writes per second. Median latency held at 13.5ms, 95th percentile at 61.8ms, and 994.9th percentile at 1,333.5ms. We consider those numbers very good for a cluster in distress, proving Compute Engine and Cassandra can handle both spiky workloads and failures.</p><p><b>Conclusion</b><br />\nTuning the workload costs $5 per hour (on a 3 node cluster), and the minimal test required to hit one million writes per second takes 1 hour and 10 minutes at a cost of $330 USD when run in March 2014. </p><p>Putting it all together, this means the Google Cloud Platform was able to sustain <b>one million Cassandra writes per second at a cost of $0.07 USD per million writes</b>.</p><p>-Posted by Ivan Santa Maria Filho, Performance Engineering Lead\n\n</p></noscript>\n</div>"}}]}},"pageContext":{"alternative_id":12076}}