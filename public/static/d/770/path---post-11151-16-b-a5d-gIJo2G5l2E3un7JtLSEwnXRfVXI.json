{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Tuning DSE Search – Indexing latency and query latency","alternative_id":11151,"content":"<p>DataStax Enterprise offers out of the box search indexing for your Apache Cassandra™ data. The days of double writes or ETL's between separate DBMS and Search clusters are gone. I have my CQL table, I execute the following API call, and (boom) my Cassandra data is available for:</p><p>1) full text/fuzzy search</p><p>2) ad hoc Lucene secondary index powered filtering, and</p><p>3) geospatial searchHere is my API call:</p><pre>$ bin/dsetool create_core &lt;keyspace&gt;.&lt;table&gt; generateResources=true reindex=true&#13;\n</pre><p>or if you prefer curl (or are using basic auth) use the following:</p><pre>$ curl \"http://localhost:8983/solr/admin/cores?action=CREATE&amp;name=&lt;keyspace&gt;.&lt;table&gt;&amp;generateResources=true\"&#13;\n</pre><p>Rejoice! we are in inverted index, single cluster, operational simplicity bliss!</p><p>The remainder of this post will be focused on <strong>advanced tuning</strong> for DSE Search both for <strong>a)</strong> search indexing latency (the time it takes for data to be searchable after it has been inserted through cql), and <strong>b)</strong> search query latency (timings for your search requests).</p><h2 id=\"indexinglatency\">Indexing latency</h2><p>In this section I'll talk about the kinds of things we can do in order to</p><p>1) instrument and monitor DSE Search indexing and<br />2) tune indexing for lower latencies and increased performance</p><p><strong>Note</strong>: DSE Search ships with Real Time (RT) indexing which will give you faster indexing with 4.7.3, especially when it comes to the tails of your latency distribution. Here's one of our performance tests. It shows you real time vs near-real time indexing as of 4.7.0:</p><p><img class=\"\" src=\"https://s3.amazonaws.com/uploads.hipchat.com/6528/1116934/P10Ckn4e4cijTf0/upload.png\" alt=\"indexing chart\" width=\"488\" height=\"302\" /></p><p>Perhaps more importantly, as you get machines with more cores, you can continue to increase your indexing performance linearly:<br /><img class=\"\" src=\"https://s3.amazonaws.com/uploads.hipchat.com/6528/1116934/5OFvz6SgZsl68b1/Screen%20Shot%202016-03-15%20at%2011.03.22%20PM.png\" alt=\"rt vs nrt\" width=\"480\" height=\"302\" /></p><p>Be aware, however, that you should only run one RT search core per cluster since it is significantly more resource hungry than near-real time (NRT).</p><p><strong>Side note on GC</strong>: Because solr and Cassandra run on the same JVM in DSE Search and the indexing process generates a lot of java objects, running Search requires a larger JVM Heap. When running traditional <strong>CMS</strong>, we recommend a 14gb heap with about 2gb new gen. Consider the Stump's <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-8150\">CASSANDRA-8150</a> settings when running search with CMS. <strong>G1GC</strong> has been found to perform quite well with search workloads, I personally run with a 25gb heap (do not set new gen with G1, the whole point of G1 is that it sets it itself based on your workload!) and <code>gc_pause_ms</code> at about 1000 (go higher for higher throughput or lower to minimize latencies / p99's; don't go below 500). Update (thanks mc) you configure this setting in cassandra-env.sh.</p><h3 id=\"1instrumentation\">1) Instrumentation</h3><p><strong>Index Pool Stats:</strong></p><p>DSE Search parallelizes the indexing process and allocates work to a thread pool for indexing of your data.</p><p>Using JMX, you can see statistics on your indexing threadpool depth, completion, timings, and whether backpressure is active.</p><p>This is important because if your indexing queues get too deep, we risk having too much heap pressure =&gt; OOM's. Backpressure will throttle commits and eventually load shed if search can't keep up with an indexing workload. Backpressure gets triggered when the queues get too large.</p><p>The mbean is called:</p><pre>com.datastax.bdp.search.&lt;keyspace&gt;.&lt;table&gt;.IndexPool&#13;\n</pre><p><img class=\"\" src=\"https://s3.amazonaws.com/uploads.hipchat.com/6528/1116934/ObHJEFKOEuQnLm8/upload.png\" alt=\"Indexing queues\" width=\"523\" height=\"287\" /></p><p><strong>Commit/Update Stats:</strong></p><p>You can also see statistics on indexing performance (in microseconds) based on the particular stage of the indexing process for both <code>commit</code>s and <code>update</code>s.</p><p><strong>Commit:</strong></p><p>The stages are:</p><ul><li><code>FLUSH</code> - Comprising the time spent by flushing the async indexing queue.</li>\n<li><code>EXECUTE</code> - Comprising the time spent by actually executing the commit on the index.</li>\n</ul><p>The mbean is called:</p><ul><li><code>com.datastax.bdp.search.&lt;keyspace&gt;.&lt;table&gt;.CommitMetrics</code></li>\n</ul><p><strong>Update:</strong></p><p>The stages are:</p><ul><li><code>WRITE</code> - Comprising the time spent to convert the Solr document and write it into Cassandra (only available when indexing via the Solrj HTTP APIs). If you're using cql this will be 0.</li>\n<li><code>QUEUE</code> - Comprising the time spent by the index update task into the index pool.</li>\n<li><code>PREPARE</code>- Comprising the time spent preparing the actual index update.</li>\n<li><code>EXECUTE</code> - Comprising the time spent to actually executing the index update on Lucene.</li>\n</ul><p>The mbean is:</p><ul><li><code>`com.datastax.bdp.search.&lt;keyspace&gt;.&lt;table&gt;.UpdateMetrics` </code></li>\n</ul><p><img class=\"\" src=\"https://s3.amazonaws.com/uploads.hipchat.com/6528/1116934/CLrZrQNbRatrmck/upload.png\" alt=\"indexing stats\" width=\"524\" height=\"308\" /></p><p>Here, the average latency for the QUEUE stage of the <code>update</code> is 767 micros. See our docs for more details on the <a href=\"https://docs.datastax.com/en/datastax_enterprise/5.0/datastax_enterprise/srch/metricsMBeans.html\">metrics mbeans</a> and their stages.</p><h3 id=\"2tuning\">2) Tuning</h3><p>Almost everything in c* and DSE is configurable. Here's the key levers to get you better search indexing performance. Based on what you see in your instrumentation you can tune accordingly.</p><p>The main lever is <code>soft autocommit</code>, that's the minimum amount of time that will go by before queries are available for search. With RT we can set it to 250 ms or even as low as 100ms--given the right hardware. Tune this based on your SLA's.</p><p>The next most important lever is concurrency per core (or <code>max_solr_concurrency_per_core</code>). You can usually set this to number of CPU cores available to maximize indexing throughput.</p><p>Backpressure threshold will become more important as your load increases. Larger boxes can handle higher bp thresholds.</p><p>Don't forget to set up the ramBuffer to 2gb per the docs when you turn on RT indexing.</p><h2 id=\"querylatency\">Query Latency</h2><p>Now, I'll go over how we can monitor query performance in DSE Search, identify issues, and some of the tips / tricks we can use to improve search query performance. I will cover how to:</p><p>1) instrument and monitor DSE Search indexing and<br />2) tune indexing for lower latencies and increased performance.</p><p>Simliar to how search indexing performance scales with CPU's, search query performance scales with RAM. Keeping your search indexes in OS page cache is the biggest thing you can do to minimize latencies; so scale deliberately!</p><h3>1) Instrumentation</h3><p>There are multiple tools available for monitoring search performance.</p><h4 id=\"opscenter\">OpsCenter:</h4><p>OpsCenter supports a few search metrics that can be configured per node, datacenter, and solr core:</p><p>1) search latencies<br />2) search requests<br />3) index size<br />4) search timeouts<br />5) search errors</p><p><img class=\"\" src=\"https://s3.amazonaws.com/uploads.hipchat.com/6528/1116934/uoq1hLRQ58AZBhn/Screen%20Shot%202016-03-15%20at%2011.47.12%20PM.png\" alt=\"opscenter\" width=\"368\" height=\"226\" /></p><h4 id=\"metricsmbeans\">Metrics mbeans:</h4><p>In the same way that indexing has performance metrics, DSE Search <a href=\"https://docs.datastax.com/en/datastax_enterprise/4.0/datastax_enterprise/srch/srchQryMbean.html\">query performance metrics</a> are available through JMX and can be useful for troubleshooting perofrmance issues. We can use the <code>query.name</code> parameter in your DSE Search queries to capture metrics for specifically tagged queries.</p><p><strong>Query:</strong></p><p>The stages of <code>query</code> are:</p><ul><li><code>COORDINATE</code> - Comprises the total amount of time spent by the coordinator node to distribute the query and gather/process results from shards. This value is computed only on query coordinator nodes.</li>\n<li><code>EXECUTE</code> - Comprises the time spent by a single shard to execute the actual index query. This value is computed on the local node executing the shard query.</li>\n<li><code>RETRIEVE</code> - Comprises the time spent by a single shard to retrieve the actual data from Cassandra. This value will be computed on the local node hosting the requested data.</li>\n</ul><p>The mbean is:</p><ul><li><code>com.datastax.bdp.search.&lt;keyspace&gt;.&lt;table&gt;.QueryMetrics </code></li>\n</ul><h4 id=\"querytracing\">Query Tracing:</h4><p>When using <code>solr_query</code> via cql, query tracing can provide useful information as to where a particular query spent time in the cluster.</p><p>Query tracing is available in cqlsh <code>tracing on</code>, in DevCenter (in the tab at the bottom of the screen), and via probabilistic tracing which is configurable via <a href=\"https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsSetTraceProbability.html\">nodetool</a>.</p><p>When users complain about a slow query and you need to find out what it is, the DSE Search slow query log is a good starting point.</p><pre>dsetool perf solrslowlog enable&#13;\n</pre><p>Stores to a table in cassandra in the <code>dse_perf.solr_slow_sub_query_log</code> table</p><h3>2) Tuning</h3><p>Now let's focus on some tips for how you can improve search query performance.</p><h3 id=\"indexsize\">Index size</h3><p>Index size is so important that, I wrote <a href=\"http://www.sestevez.com/solr-space-saving-profile/\">a separate post</a> just on that subject.</p><h4 id=\"qvsfq\">Q vs. FQ</h4><p>In order to take advantage of the solr filter cache, build your queries using fq not q. The filter cache is the only solr cache that persists across commits so don't spend time or valuable RAM trying to leverage the other caches.</p><h4 id=\"solrqueryrouting\">Solr query routing</h4><p>Partition routing is a great multi-tennancy feature in DSE Search that lets you limit the amount of fan out that a search query will take under the hood. Essentially, you're able to specify a Cassandra partition that you are interested in limiting your search to. This will limit the number of nodes that DSE Search requires to fullfil your request.</p><h4 id=\"usedocvaluesforfacetingandsorting\">Use docvalues for Faceting and Sorting.</h4><p>To get improved performance and to avoid OOMs from the field cache, always remember to turn on docvalues on fields that you will be sorting and faceting over. This may become mandatory in DSE at some point so plan ahead.</p><h3 id=\"otherdsedifferentiators\">Other DSE Differentiators</h3><p>If you're comparing DSE Search against other search offerings / technologies, the following two differentiators are unique to DSE Search.</p><h4 id=\"faulttolerantdistributedqueries\">Fault tolerant distributed queries</h4><p>If a node dies during a query, we retry the query on another node.</p><h4 id=\"nodehealth\">Node health</h4><p>Node health and shard router behavior.<br />DSE Search monitors node health and makes distributed query routing decisions based on the following:</p><p>1) Uptime: a node that just started may well be lacking the most up-to-date data (to be repaired via HH or AE).<br />2) Number of dropped mutations.<br />3) Number of hints the node is a target for.<br />4) \"failed reindex\" status.</p><p>All you need to take advantage of this is be on a modern DSE version.</p><hr /><p><a href=\"https://www.datastax.com/\">DataStax</a> has many ways for you to advance in your career and knowledge. \n</p><p>You can take <a href=\"https://academy.datastax.com/user/register?destination=home&amp;utm_campaign=DevBlog&amp;utm_medium=blog&amp;utm_source=devblog&amp;utm_term=DevBlogPosts_CTA1_DSA_register\" target=\"_self\" title=\"academy.datastax.com\">free classes</a>, <a href=\"https://academy.datastax.com/certifications?utm_campaign=DevBlog&amp;utm_medium=blog&amp;utm_source=devblog&amp;utm_term=DevBlogPosts_CTA1_DSA_certifications\" target=\"_self\" title=\"academy.datastax.com/certifications\">get certified</a>, or read <a href=\"https://www.datastax.com/dbas-guide-to-nosql\" target=\"_self\" title=\"dbas-guide-to-nosql\">one of our many white papers</a>.\n</p><p><a href=\"https://academy.datastax.com/user/register?destination=home&amp;utm_campaign=DevBlog&amp;utm_medium=blog&amp;utm_source=devblog&amp;utm_term=DevBlogPosts_CTA1_DSA_register\" target=\"_self\" class=\"dxAllButtons_v3Rad2_whiteNGrayOL\" title=\"academy.datastax.com\">register for classes</a>\n</p><p><a href=\"https://academy.datastax.com/certifications?utm_campaign=DevBlog&amp;utm_medium=blog&amp;utm_source=devblog&amp;utm_term=DevBlogPosts_CTA1_DSA_certifications\" target=\"_self\" class=\"dxAllButtons_v3Rad2_whiteNGrayOL\" title=\"academy.datastax.com/certifications\">get certified</a>\n</p><p><a href=\"http://www.datastax.com/dbas-guide-to-nosql?utm_campaign=DevBlog&amp;utm_medium=blog&amp;utm_source=devblog&amp;utm_term=DevBlogPosts_CTA1_dbasguidetonosql\" target=\"_self\" class=\"dxAllButtons_v3Rad2_whiteNGrayOL\" title=\"dbas-guide-to-nosql\">DBA's Guide to NoSQL</a>\n</p><br class=\"clear\" /><div id=\"mto_newsletter_121316_Css\"><p>Subscribe for newsletter:</p><br /></div>"}}]}},"pageContext":{"alternative_id":11151}}