{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Null bindings on prepared statements and undesired tombstone creation","alternative_id":1465,"content":"<p>As explained “in extenso” by Alain <a href=\"http://thelastpickle.com/blog/2016/07/27/about-deletes-and-tombstones.html\">in his installment on how Apache Cassandra deletes data</a>, removing rows or cells from a table is done by a special kind of write called a tombstone. But did you know that inserting a null value into a field from a CQL statement also generates a tombstone? This happens because Cassandra cannot decide whether inserting a null value means that we are trying to void a field that previously had a value or that we do not want to insert a value for that specific field.</p><p>In this article, we will show examples of how this can happen, how to detect it, and what you can do to mitigate it.</p>\n<h2 id=\"aggressive-tombstone-purging-in-cassandra\">Aggressive tombstone purging in Cassandra</h2>\n<p>Before we go into detail on how to avoid generating tombstones from inserting null columns, we will briefly discuss aggressive tombstone purging via single SSTable compactions, as we reference one of these settings in the rest of the article.</p>\n<p>Single SSTable compactions can be triggered automatically by Cassandra to clear tombstones from SSTables even when they do not match standard SSTable compaction criteria. This feature is very important in reducing disk space issues and is triggered based on compaction parameters that are not well known to many Cassandra users.</p>\n<p>Every compaction strategy has the following three parameters to control the single SSTable compaction process :</p>\n<ul><li>tombstone_threshold: the percentage of the table which must be occupied by tombstones for a single SSTable compaction to occur (default 0.2)</li>\n  <li>tombstone_compaction_interval: the number of seconds since the SSTable was created after which it can be considered for single SSTable compaction (default 86,400 which is one day)</li>\n  <li>unchecked_tombstone_compaction: check for overlap with other SSTables before running a single SSTable compaction</li>\n</ul><p>We won’t be detailing the entire process here, but instead focus on the tombstone_threshold value and how this impacts cleaning up tombstones generated from null columns.</p>\n<p>Using the DataStax Java Driver we’ll illustrate how we can generate tombstones and how they manifest themselves in SSTables.</p>\n<p>Considering the following Cassandra table  :</p>\n<div class=\"highlighter-rouge\"><pre>CREATE TABLE myks.mytable (\n    id int PRIMARY KEY,\n    value1 text,\n    value2 text,\n    value3 text\n);\n</pre>\n</div>\n<p>We’re going to insert a row using a prepared statement with the DataStax Java driver v3.0.0 :</p>\n<div class=\"highlighter-rouge\"><pre>Cluster cluster = Cluster.builder().addContactPoint(\"127.0.0.1\").build();\nSession session = cluster.connect();\nPreparedStatement prepStmt = session.prepare(\"INSERT INTO myks.mytable(id, value1, value2, value3) values(?, ?, ?, ?)\");\nBoundStatement boundStmt = prepStmt.bind(1, \"value1\", null);\nsession.execute(boundStmt);\nsession.close();\ncluster.close();\n</pre>\n</div>\n<p>Here we can see that field <strong>value2</strong> as been explicitly set to null and field <strong>value3</strong> has deliberately not been bound to any value.</p>\n<p>After flushing the memtable using <code class=\"highlighter-rouge\">nodetool flush</code> on a Cassandra 3.0.8 CCM cluster and convert the resulting SSTable to JSON we get the following output :</p>\n<div class=\"highlighter-rouge\"><pre>[\n  {\n    \"partition\" : {\n      \"key\" : [ \"1\" ],\n      \"position\" : 0\n    },\n    \"rows\" : [\n      {\n        \"type\" : \"row\",\n        \"position\" : 18,\n        \"liveness_info\" : { \"tstamp\" : \"2016-09-10T02:14:32.215Z\" },\n        \"cells\" : [\n          { \"name\" : \"value1\", \"value\" : \"value1\" },\n          { \"name\" : \"value2\", \"deletion_info\" : { \"local_delete_time\" : \"2016-09-10T02:14:32Z\" }\n          }\n        ]\n      }\n    ]\n  }\n]\n</pre>\n</div>\n<p>The <code class=\"highlighter-rouge\">deletion_info</code> on the <strong>value2</strong> field shows that we have a tombstone, while value3 is absent from the output.</p>\n<p>The combination of Cassandra 2.2+ and DataStax Java Driver 3.0+ prevents unset bind parameters from generating tombstones, while binding null values actually generates tombstones.</p>\n<p>Taking a look at our SSTable’s metadata, we can see that the estimated droppable tombstone ratio is already above the default threshold :</p>\n<div class=\"highlighter-rouge\"><pre>MacBook-Pro:mytable-1f1f9b2076fc11e69df3a5416e6d241c adejanovski$ sstablemetadata mb-1-big-Data.db | grep droppable\nEstimated droppable tombstones: 0.25000048441443046\n</pre>\n</div>\n<p>The problem here is that this cell tombstone will not get evicted until the whole row gets its very own tombstone, which will have to live more then the configured <strong>gc_grace_seconds</strong> to eventually be eligible for actual purge during the next compaction.</p>\n<p>Using the default <strong>tombstone_threshold</strong> will generate an important write amplification here as the SSTable will be compacted and fully rewritten at each cycle until the row can actually be fully purged (and we won’t be covering partition fragmentation over multiple SSTables and timestamp overlaps that can further delay tombstone purges, for the sake of simplicity).</p>\n<p>We can observe this behavior by running a major compaction on the table and checking the newly create SSTable size and estimated droppable tombstone ratio:</p>\n<div class=\"highlighter-rouge\"><pre>MacBook-Pro:mytable-1f1f9b2076fc11e69df3a5416e6d241c adejanovski$ sstablemetadata mb-2-big-Data.db | grep droppable\nEstimated droppable tombstones: 0.25000135458119405\n</pre>\n</div>\n<p>Checking the content by using <code class=\"highlighter-rouge\">sstabledump</code> shows that the tombstone is indeed still present as we get the exact same output.</p>\n<p>The good news here is that we can avoid creating unnecessary tombstones by not binding parameters instead of setting them to a null value.</p>\n<p>Running the same code on a 2.1 cluster will give a slightly different result though :</p>\n<div class=\"highlighter-rouge\"><pre>Exception in thread \"main\" java.lang.IllegalStateException: Unset value at index 3. If you want this value to be null, please set it to null explicitly.\n\tat com.datastax.driver.core.BoundStatement.ensureAllSet(BoundStatement.java:1351)\n\tat com.datastax.driver.core.SessionManager.makeRequestMessage(SessionManager.java:572)\n\tat com.datastax.driver.core.SessionManager.executeAsync(SessionManager.java:131)\n\tat com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:63)\n\tat com.thelastpickle.java_driver.prepstmttest.App.main(App.java:23)\n</pre>\n</div>\n<p>Indeed, the ability to avoid tombstone creation by not binding specific parameters needs a combination of the DataStax Java Driver 3.0.0 and Cassandra 2.2+.</p>\n<h2 id=\"workarounds\">Workarounds</h2>\n<p>If still running an earlier version of Cassandra, and at the time of this writing most production clusters may still be running Cassandra 2.0 or 2.1, there are a few options to save nodes from tombstone pollution.</p>\n<p>If we can easily predict which fields are likely to be null, it is possible to prepare 2 or 3 statements that will cover different combinations of fields. This way we get to choose the statement that will not generate tombstones, or at least as few as possible based on the values to be bound.</p>\n<p>If the number of field combinations gets too high the above technique is not an option, but we can still take advantage of batches to fix that issue.</p>\n<p>While big batches, and especially multi partition batches, are generally not advised because of the pressure they put on coordinator nodes, small single partition batches are a very efficient way to group queries.\nIn this case, we can generate a set of prepared statement for each field (or group of fields) and group their execution into batches :</p>\n<div class=\"highlighter-rouge\"><pre>Cluster cluster = Cluster.builder().addContactPoint(\"127.0.0.1\").build();\nSession session = cluster.connect();\nString value1 = \"value1\";\nString value2 = null;\nString value3 = null;\nPreparedStatement prepStmt1 = session.prepare(\"INSERT INTO myks.mytable(id, value1) values(?, ?)\");\nPreparedStatement prepStmt2 = session.prepare(\"INSERT INTO myks.mytable(id, value2) values(?, ?)\");\nPreparedStatement prepStmt3 = session.prepare(\"INSERT INTO myks.mytable(id, value3) values(?, ?)\");\nList&lt;BoundStatement&gt; boundStatements = new ArrayList&lt;&gt;();\nif(value1!=null){\n\tboundStatements.add(prepStmt1.bind(2, value1));\n}\nif(value2!=null){\n\tboundStatements.add(prepStmt2.bind(2, value2));\n}\nif(value3!=null){\n\tboundStatements.add(prepStmt3.bind(2, value3));\n}\nfinal BatchStatement batch = new BatchStatement();\nboundStatements.forEach(stmt -&gt; batch.add(stmt));\nsession.execute(batch);\nsession.close();\ncluster.close();\n</pre>\n</div>\n<p>After running this code against our 2.1 cluster and flushing the SSTable we can observe that no tombstones were generated :</p>\n<div class=\"highlighter-rouge\"><pre>MacBook-Pro:mytable-b3a24e50770111e6bab5a9eb710f2b22 adejanovski$ sstablemetadata myks-mytable-ka-1-Data.db | grep droppable\nEstimated droppable tombstones: 0.0\n</pre>\n</div>\n<p>Batches are processed atomically on each partition, as a single operation against the database, making them as efficient as running a single query, but allowing us more flexibility in this specific use case to get a more tombstone efficient application.</p>\n<p>If changing production code and deploying a new application is not possible in a decent amount of time, try to observe at which droppable tombstone ratio the SSTables actually get the ability to purge at least a part of their content.</p>\n<p>If the data has TTL’ed, we should see an increase in the droppable tombstone ratio as the SSTables get older.\nOnce that ratio gets determined, use an alter table statement to change the threshold (adjust the following to match the compaction strategy, in our case TWCS) :</p>\n<div class=\"highlighter-rouge\"><pre>ALTER TABLE myks.mytable\nWITH compaction = {'class':'TimeWindowCompactionStrategy',\n                   'compaction_window_size': '1',\n    \t\t\t   'compaction_window_unit': 'DAYS',\n    \t\t\t   'tombstone_threshold':'0.5',\n    \t\t\t   'unchecked_tombstone_compaction':true};\n</pre>\n</div>\n<p>We recommend setting <code class=\"highlighter-rouge\">unchecked_tombstone_compaction</code> to <code class=\"highlighter-rouge\">true</code> as it will allow single SSTable compactions to run more often even if all droppable tombstones won’t necessarily get purged due to SSTables overlap. In any case, a safety check will be performed before any tombstone purge to prevent data loss.</p>\n<p>Adjusting the threshold will prevent Cassandra from wasting I/O and CPU on useless compactions and still trigger them to reclaim disk space when possible.</p>\n<h2 id=\"takeaways\">Takeaways</h2>\n<p>Prepared statements are highly recommended when interacting with Cassandra as they remove some overhead compared to simple statements and effectively allow the driver to use the TokenAwarePolicy, which lightens the coordination footprint of the cluster.</p>\n<p>On all combinations of Cassandra and Java driver versions, binding null values to prepared statement parameters will generate tombstones, and leaving unset bound parameters is only possible with Cassandra 2.2+ combined with the DataStax Java Driver 3.0.0+.</p>\n<p>Those tombstones will force Cassandra to overestimate droppable tombstone ratios and make the use of aggressive tombstone purging strategies more complex to tune.</p>\n<p>To efficiently detect this kind of behavior without a full codebase audit, use the <code class=\"highlighter-rouge\">sstablemetadata</code> command on newly flushed SSTables. They should have a ratio that is very close to 0 if deletes are not performed and the TTLs are longer than the time between the insert and the SSTable flush. With this information, you can then tweak the application code and table compaction settings in order to stop generating tombstones and allow the tombstone purge strategy to run efficiently.</p>"}}]}},"pageContext":{"alternative_id":1465}}