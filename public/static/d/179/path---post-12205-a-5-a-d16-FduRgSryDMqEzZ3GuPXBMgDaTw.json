{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Apache Drill Contribution Ideas - Apache Drill","alternative_id":12205,"content":"<ul><li>Fixing JIRAs</li>\n<li>SQL functions </li>\n<li>Support for new file format readers/writers</li>\n<li>Support for new data sources</li>\n<li>New query language parsers</li>\n<li>Application interfaces\n<ul><li>BI Tool testing</li>\n</ul></li>\n<li>General CLI improvements </li>\n<li>Eco system integrations\n<ul><li>MapReduce</li>\n<li>Hive views</li>\n<li>YARN</li>\n<li>Spark</li>\n<li>Hue</li>\n<li>Phoenix</li>\n</ul></li>\n</ul><h2 id=\"fixing-jiras\">Fixing JIRAs</h2><p>This is a good place to begin if you are new to Drill. Feel free to pick\nissues from the Drill JIRA list. When you pick an issue, assign it to\nyourself, inform the team, and start fixing it.</p><p>For any questions, seek help from the team through the <a href=\"http://drill.apache.org/community/#mailinglists\">mailing list</a>.</p><p><a href=\"https://issues.apache.org/jira/browse/DRILL/?selectedTab=com.atlassian.jira%0A.jira-projects-plugin:summary-panel\">https://issues.apache.org/jira/browse/DRILL/?selectedTab=com.atlassian.jira\n.jira-projects-plugin:summary-panel</a></p><p>One of the next simple places to start is to implement a DrillFunc. DrillFuncs\nis way that Drill express all scalar functions (UDF or system).  First you can\nput together a JIRA for one of the DrillFunc's we don't yet have but should\n(referencing the capabilities of something like Postgres or SQL Server or your\nown use case). Then try to implement one.</p><p>One example DrillFunc:<br /><a href=\"https://github.com/apache/drill/blob/3f93454f014196a4da198ce012b605b70081fde0/exec/java-exec/src/main/codegen/templates/ComparisonFunctions.java\">ComparisonFunctions.java</a></p><hr /><p><strong>Additional ideas on functions that can be added to SQL support</strong></p><ul><li>Madlib integration</li>\n<li>Machine learning functions</li>\n<li>Approximate aggregate functions (such as what is available in BlinkDB)</li>\n</ul><h2 id=\"support-for-new-file-format-readers/writers\">Support for new file format readers/writers</h2><p>Currently Drill supports text, JSON and Parquet file formats natively when\ninteracting with file system. More readers/writers can be introduced by\nimplementing custom storage plugins. Example formats are.</p><ul><li>Sequence</li>\n<li>RC</li>\n<li>ORC</li>\n<li>Protobuf</li>\n<li>XML</li>\n<li>Thrift</li>\n</ul><h2 id=\"support-for-new-data-sources\">Support for new data sources</h2><p>Writing a new file-based storage plugin, such as a JSON or text-based storage plugin, simply involves implementing a couple of interfaces. The JSON storage plugin is a good example. </p><p>You can refer to the github commits to the mongo db and hbase storage plugin for implementation details: </p><ul><li><a href=\"https://github.com/apache/drill/commit/2ca9c907bff639e08a561eac32e0acab3a0b3304\">mongodb_storage_plugin</a></li>\n<li><a href=\"https://github.com/apache/drill/commit/3651182141b963e24ee48db0530ec3d3b8b6841a\">hbase_storage_plugin</a></li>\n</ul><p>Focus on implementing/extending this list of classes and the corresponding implementations done by Mongo and Hbase. Ignore the mongo db plugin optimizer rules for pushing predicates into the scan.</p><p>Initially, concentrate on basics:</p><ul><li>AbstractGroupScan (MongoGroupScan, HbaseGroupScan)<br /></li>\n<li>SubScan (MongoSubScan, HbaseSubScan)<br /></li>\n<li>RecordReader (MongoRecordReader, HbaseRecordReader)<br /></li>\n<li>BatchCreator (MongoScanBatchCreator, HbaseScanBatchCreator)<br /></li>\n<li>AbstractStoragePlugin (MongoStoragePlugin, HbaseStoragePlugin)<br /></li>\n<li>StoragePluginConfig (MongoStoragePluginConfig, HbaseStoragePluginConfig)</li>\n</ul><p>Implement custom storage plugins for the following non-Hadoop data sources:</p><ul><li>NoSQL databases (such as Mongo, Cassandra, Couch etc)</li>\n<li>Search engines (such as Solr, Lucidworks, Elastic Search etc)</li>\n<li>SQL databases (MySQL&lt; PostGres etc)</li>\n<li>Generic JDBC/ODBC data sources</li>\n<li>HTTP URL</li>\n<li>----</li>\n</ul><h2 id=\"new-query-language-parsers\">New query language parsers</h2><p>Drill exposes strongly typed JSON APIs for logical and physical plans. Drill provides a\nSQL language parser today, but any language parser that can generate\nlogical/physical plans can use Drill's power on the backend as the distributed\nlow latency query execution engine along with its support for self-describing\ndata and complex/multi-structured data.</p><ul><li>Pig parser : Use Pig as the language to query data from Drill. Great for existing Pig users.</li>\n<li>Hive parser : Use HiveQL as the language to query data from Drill. Great for existing Hive users.</li>\n</ul><h2 id=\"application-interfaces\">Application interfaces</h2><p>Drill currently provides JDBC/ODBC drivers for the applications to interact\nalong with a basic version of REST API and a C++ API. The following list\nprovides a few possible application interface opportunities:</p><ul><li>Enhancements to REST APIs (<a href=\"https://issues.apache.org/jira/browse/DRILL-77\">https://issues.apache.org/jira/browse/DRILL-77</a>)</li>\n<li>Expose Drill tables/views as REST APIs</li>\n<li>Language drivers for Drill (python etc)</li>\n<li>Thrift support</li>\n<li>....</li>\n</ul><p>Drill provides JDBC/ODBC drivers to connect to BI tools. We need to make sure\nDrill works with all major BI tools. Doing a quick sanity testing with your\nfavorite BI tool is a good place to learn Drill and also uncover issues in\nbeing able to do so.</p><h2 id=\"general-cli-improvements\">General CLI improvements</h2><p>Currently Drill uses SQLLine as the CLI. The goal of this effort is to improve\nthe CLI experience by adding functionality such as execute statements from a\nfile, output results to a file, display version information, and so on.</p><h2 id=\"eco-system-integrations\">Eco system integrations</h2><h3 id=\"mapreduce\">MapReduce</h3><p>Allow using result set from Drill queries as input to the Hadoop/MapReduce\njobs.</p><h3 id=\"hive-views\">Hive views</h3><p>Query data from existing Hive views using Drill queries. Drill needs to parse\nthe HiveQL and translate them appropriately (into Drill's SQL or\nlogical/physical plans) to execute the requests.</p><h3 id=\"yarn\">YARN</h3><p><a href=\"https://issues.apache.org%0A/jira/browse/DRILL-1170\">https://issues.apache.org/jira/browse/<em>DRILL</em>-1170</a></p><h2 id=\"spark\">Spark</h2><p>Provide ability to invoke Drill queries as part of Apache Spark programs. This\ngives ability for Spark developers/users to leverage Drill richness of the\nquery layer , for data source access and as low latency execution engine.</p><h3 id=\"hue\">Hue</h3><p>Hue is a GUI for users to interact with various Hadoop eco system components\n(such as Hive, Oozie, Pig, HBase, Impala ...). The goal of this project is to\nexpose Drill as an application inside Hue so users can explore Drill metadata\nand do SQL queries.</p><h3 id=\"phoenix\">Phoenix</h3><p>Phoenix provides a low latency query layer on HBase for operational\napplications. The goal of this effort is to explore opportunities for\nintegrating Phoenix with Drill.</p><p><a href=\"https://drill.apache.org/docs/apache-drill-contribution-guidelines/\">← Apache Drill Contribution Guidelines</a><a href=\"https://drill.apache.org/docs/design-docs/\">Design Docs →</a></p>"}}]}},"pageContext":{"alternative_id":12205}}