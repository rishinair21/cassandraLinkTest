{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Bootstrapping Apache Cassandra Nodes","alternative_id":5115,"content":"<p>Auto bootstrapping is a handy feature when it comes to growing an Apache Cassandra cluster. There are some unknowns about how this feature works which can lead to data inconsistencies in the cluster. In this post I will go through a bit about the history of the feature, the different knobs and levers available to operate it, and resolving some of the common issues that may arise.</p><p>Here are links to the various sections of the post to give you an idea of what I will cover.</p>\n<ul><li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#background\">Background</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#back-to-basics\">Back to basics (how data is distributed)</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#gotchas\">Gotchas (common mistakes and pitfalls)</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#adding-a-replacement-node\">Adding a replacement node</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#hang-on-what-about-adding-a-replacement-a-seed-node\">Hang on! What about adding a replacement a seed node?</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#what-to-do-after-it-completes-successfully\">What to do after it completes successfully</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#help-it-failed\">Help! It failed</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#testing-the-theory\">Testing the theory</a></li>\n  <li><a href=\"http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html#conclusion\">Conclusion</a></li>\n</ul><p>The bootstrap feature in Apache Cassandra controls the ability for the data in cluster to be automatically redistributed when a new node is inserted. The new node joining the cluster is defined as an empty node without system tables or data.</p>\n<p>When a new node joins the cluster using the auto bootstrap feature, it will perform the following operations</p>\n<ul><li>Contact the seed nodes to learn about gossip state.</li>\n  <li>Transition to Up and Joining state (to indicate it is joining the cluster; represented by <strong><code class=\"highlighter-rouge\">UJ</code></strong> in the <code class=\"highlighter-rouge\">nodetool status</code>).</li>\n  <li>Contact the seed nodes to ensure schema agreement.</li>\n  <li>Calculate the tokens that it will become responsible for.</li>\n  <li>Stream replica data associated with the tokens it is responsible for from the former owners.</li>\n  <li>Transition to Up and Normal state once streaming is complete (to indicate it is now part of the cluster; represented by <strong><code class=\"highlighter-rouge\">UN</code></strong> in the <code class=\"highlighter-rouge\">nodetool status</code>).</li>\n</ul><p>The above operations can be seen in the logs.</p>\n<p><strong>Contact the seed nodes to learn about gossip state</strong></p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [HANDSHAKE-/127.0.0.1] 2017-05-12 16:14:45,290 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.1\nINFO  [GossipStage:1] 2017-05-12 16:14:45,318 Gossiper.java:1029 - Node /127.0.0.1 is now part of the cluster\nINFO  [GossipStage:1] 2017-05-12 16:14:45,325 Gossiper.java:1029 - Node /127.0.0.2 is now part of the cluster\nINFO  [GossipStage:1] 2017-05-12 16:14:45,326 Gossiper.java:1029 - Node /127.0.0.3 is now part of the cluster\nINFO  [GossipStage:1] 2017-05-12 16:14:45,328 Gossiper.java:1029 - Node /127.0.0.4 is now part of the cluster\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:45,331 Gossiper.java:993 - InetAddress /127.0.0.1 is now UP\nINFO  [HANDSHAKE-/127.0.0.3] 2017-05-12 16:14:45,331 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.3\nINFO  [HANDSHAKE-/127.0.0.2] 2017-05-12 16:14:45,383 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.2\nINFO  [HANDSHAKE-/127.0.0.4] 2017-05-12 16:14:45,387 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.4\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:45,438 Gossiper.java:993 - InetAddress /127.0.0.3 is now UP\nINFO  [SharedPool-Worker-2] 2017-05-12 16:14:45,438 Gossiper.java:993 - InetAddress /127.0.0.4 is now UP\nINFO  [SharedPool-Worker-3] 2017-05-12 16:14:45,438 Gossiper.java:993 - InetAddress /127.0.0.2 is now UP\n...\nINFO  [main] 2017-05-12 16:14:46,289 StorageService.java:807 - Starting up server gossip\n</pre></div></div>\n<p><strong>Transition to Up and Joining state</strong></p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [main] 2017-05-12 16:14:46,396 StorageService.java:1138 - JOINING: waiting for ring information\n</pre></div></div>\n<p><strong>Contact the seed nodes to ensure schema agreement</strong></p>\n<p>Take note of the last entry in this log snippet.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [GossipStage:1] 2017-05-12 16:14:49,081 Gossiper.java:1029 - Node /127.0.0.1 is now part of the cluster\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:49,082 Gossiper.java:993 - InetAddress /127.0.0.1 is now UP\nINFO  [GossipStage:1] 2017-05-12 16:14:49,095 TokenMetadata.java:414 - Updating topology for /127.0.0.1\nINFO  [GossipStage:1] 2017-05-12 16:14:49,096 TokenMetadata.java:414 - Updating topology for /127.0.0.1\nINFO  [HANDSHAKE-/127.0.0.1] 2017-05-12 16:14:49,096 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.1\nINFO  [GossipStage:1] 2017-05-12 16:14:49,098 Gossiper.java:1029 - Node /127.0.0.2 is now part of the cluster\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:49,102 Gossiper.java:993 - InetAddress /127.0.0.2 is now UP\nINFO  [GossipStage:1] 2017-05-12 16:14:49,103 TokenMetadata.java:414 - Updating topology for /127.0.0.2\nINFO  [HANDSHAKE-/127.0.0.2] 2017-05-12 16:14:49,104 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.2\nINFO  [GossipStage:1] 2017-05-12 16:14:49,104 TokenMetadata.java:414 - Updating topology for /127.0.0.2\nINFO  [GossipStage:1] 2017-05-12 16:14:49,106 Gossiper.java:1029 - Node /127.0.0.3 is now part of the cluster\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:49,111 Gossiper.java:993 - InetAddress /127.0.0.3 is now UP\nINFO  [GossipStage:1] 2017-05-12 16:14:49,112 TokenMetadata.java:414 - Updating topology for /127.0.0.3\nINFO  [HANDSHAKE-/127.0.0.3] 2017-05-12 16:14:49,195 OutboundTcpConnection.java:487 - Handshaking version with /127.0.0.3\nINFO  [GossipStage:1] 2017-05-12 16:14:49,236 TokenMetadata.java:414 - Updating topology for /127.0.0.3\nINFO  [GossipStage:1] 2017-05-12 16:14:49,247 Gossiper.java:1029 - Node /127.0.0.4 is now part of the cluster\nINFO  [SharedPool-Worker-1] 2017-05-12 16:14:49,248 Gossiper.java:993 - InetAddress /127.0.0.4 is now UP\nINFO  [InternalResponseStage:1] 2017-05-12 16:14:49,252 ColumnFamilyStore.java:905 - Enqueuing flush of schema_keyspaces: 1444 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2017-05-12 16:14:49,254 Memtable.java:347 - Writing Memtable-schema_keyspaces@1493033009(0.403KiB serialized bytes, 10 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2017-05-12 16:14:49,256 Memtable.java:382 - Completed flushing .../node5/data0/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-tmp-ka-1-Data.db (0.000KiB) for commitlog position ReplayPosition(segmentId=1494569684606, position=119856)\nINFO  [InternalResponseStage:1] 2017-05-12 16:14:49,367 ColumnFamilyStore.java:905 - Enqueuing flush of schema_columnfamilies: 120419 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2017-05-12 16:14:49,368 Memtable.java:347 - Writing Memtable-schema_columnfamilies@1679976057(31.173KiB serialized bytes, 541 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2017-05-12 16:14:49,396 Memtable.java:382 - Completed flushing .../node5/data0/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-tmp-ka-1-Data.db (0.000KiB) for commitlog position ReplayPosition(segmentId=1494569684606, position=119856)\n...\nINFO  [InternalResponseStage:5] 2017-05-12 16:14:50,824 ColumnFamilyStore.java:905 - Enqueuing flush of schema_usertypes: 160 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2017-05-12 16:14:50,824 Memtable.java:347 - Writing Memtable-schema_usertypes@1946148009(0.008KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2017-05-12 16:14:50,826 Memtable.java:382 - Completed flushing .../node5/data0/system/schema_usertypes-3aa752254f82350b8d5c430fa221fa0a/system-schema_usertypes-tmp-ka-10-Data.db (0.000KiB) for commitlog position ReplayPosition(segmentId=1494569684606, position=252372)\nINFO  [main] 2017-05-12 16:14:50,404 StorageService.java:1138 - JOINING: schema complete, ready to bootstrap\n</pre></div></div>\n<p><strong>Calculate the tokens that it will become responsible for</strong></p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [main] 2017-05-12 16:14:50,404 StorageService.java:1138 - JOINING: waiting for pending range calculation\nINFO  [main] 2017-05-12 16:14:50,404 StorageService.java:1138 - JOINING: calculation complete, ready to bootstrap\nINFO  [main] 2017-05-12 16:14:50,405 StorageService.java:1138 - JOINING: getting bootstrap token\n</pre></div></div>\n<p><strong>Stream replica data associated with the tokens it is responsible for from the former owners</strong></p>\n<p>Take note of the first and last entries in this log snippet.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [main] 2017-05-12 16:15:20,440 StorageService.java:1138 - JOINING: Starting to bootstrap...\nINFO  [main] 2017-05-12 16:15:20,461 StreamResultFuture.java:86 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Executing streaming plan for Bootstrap\nINFO  [StreamConnectionEstablisher:1] 2017-05-12 16:15:20,462 StreamSession.java:220 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Starting streaming to /127.0.0.1\nINFO  [StreamConnectionEstablisher:2] 2017-05-12 16:15:20,462 StreamSession.java:220 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Starting streaming to /127.0.0.2\nINFO  [StreamConnectionEstablisher:3] 2017-05-12 16:15:20,462 StreamSession.java:220 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Starting streaming to /127.0.0.3\nINFO  [StreamConnectionEstablisher:1] 2017-05-12 16:15:20,478 StreamCoordinator.java:209 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3, ID#0] Beginning stream session with /127.0.0.1\nINFO  [StreamConnectionEstablisher:2] 2017-05-12 16:15:20,478 StreamCoordinator.java:209 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3, ID#0] Beginning stream session with /127.0.0.2\nINFO  [StreamConnectionEstablisher:3] 2017-05-12 16:15:20,478 StreamCoordinator.java:209 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3, ID#0] Beginning stream session with /127.0.0.3\nINFO  [STREAM-IN-/127.0.0.2] 2017-05-12 16:15:24,339 StreamResultFuture.java:166 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3 ID#0] Prepare completed. Receiving 11 files(10176549820 bytes), sending 0 files(0 bytes)\nINFO  [STREAM-IN-/127.0.0.3] 2017-05-12 16:15:27,201 StreamResultFuture.java:180 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Session with /127.0.0.3 is complete\nINFO  [STREAM-IN-/127.0.0.1] 2017-05-12 16:15:33,256 StreamResultFuture.java:180 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Session with /127.0.0.1 is complete\nINFO  [StreamReceiveTask:1] 2017-05-12 16:36:31,249 StreamResultFuture.java:180 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] Session with /127.0.0.2 is complete\nINFO  [StreamReceiveTask:1] 2017-05-12 16:36:31,256 StreamResultFuture.java:212 - [Stream #604b5690-36da-11e7-aeb6-9d89ad20c2d3] All sessions completed\nINFO  [main] 2017-05-12 16:36:31,257 StorageService.java:1167 - Bootstrap completed! for the tokens [1577102245397509090, -713021257351906154, 5943548853755748481, -186427637333122985, 89474807595263595, -3872409873927530770, 269282297308186556, -2090619435347582830, -7442271648674805532, 1993467991047389706, 3250292341615557960, 3680244045045170206, -6121195565829299067, 2336819841643904893, 8366041580813128754, -1539294702421999531, 5559860204752248078, 4990559483982320587, -5978802488822380342, 7738662906313460122, -8543589077123834538, 8470022885937685086, 7921538168239180973, 5167628632246463806, -8217637230111416952, 7867074371397881074, -6728907721317936873, -5403440910106158938, 417632467923200524, -5024952230859509916, -2145251677903377866, 62038536271402824]\n</pre></div></div>\n<p><strong>Transition to Up and Normal state once streaming is complete</strong></p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>INFO  [main] 2017-05-12 16:36:31,348 StorageService.java:1715 - Node /127.0.0.5 state jump to NORMAL\n</pre></div></div>\n<p>During the bootstrapping process, the new node joining the cluster has no effect on the existing data in terms of Replication Factor (RF). However, the new node will accept new writes for the token ranges acquired while existing data from the other nodes is being streamed to it. This ensures that no new writes are missed while data changes hands. In addition, it ensures that Consistency Level (CL) is respected all the time during the streaming process and even in the case of bootstrap failure. Once the bootstrapping process for the new node completes, it will begin to serve read requests (and continue to receive writes). Like the pre-existing nodes in the cluster, it too will then have an effect on the data in terms of RF and CL.</p>\n<p>While the bootstrapping feature can be a time saver when expanding a cluster, there are some “gotchas” that are worth noting. But before we do, we need first revisit some basics.</p>\n<p>Cassandra uses a token system to work out which nodes will hold which partition keys for the primary replica of data. To work out where data is stored in the cluster, Cassandra will first apply a hashing function to the partition key. The generated hash is then used to calculate a token value using an algorithm; most commonly <a href=\"https://en.wikipedia.org/wiki/MurmurHash\">Murmur3</a> or RandomPartitioner.</p>\n<p>As seen from the log snippets, when a new node is added to the cluster it will calculate the tokens of the different data replicas that is to be responsible for. This process where tokens are calculated and acquired by the new node is often referred to as a range movement. i.e. token ranges are being moved between nodes. Once the range movement has completed, the node will by default begin the bootstrapping process where it streams data for the acquired tokens from other nodes.</p>\n<h2 id=\"range-movements\">Range movements</h2>\n<p>Whilst range movements may sound simple, the process can create implications with maintaining data consistency. A number of patches have been added over time to help maintain data consistency during range movements. A fairly well known issue was <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2434\">CASSANDRA-2434</a> where it was highlighted that range movements violated consistency for Apache Cassandra versions below 2.1.x using vnodes.</p>\n<p>A fix was added for the issue <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2434\">CASSANDRA-2434</a> to ensure range movements between nodes were consistent when using vnodes. Prior to this patch inconsistencies could be caused during bootstrapping as per the example Jeff Jirsa gave on the <a href=\"https://lists.apache.org/thread.html/8aad2e853fc0b722aaada382352bc2c187623fddf7ae4a7a0d2fa788@%3Cdev.cassandra.apache.org%3E\">dev mailing list</a>.</p>\n<p>Consider the case of a cluster containing three nodes A, B and D with a RF of 3. If node B was offline and a key ‘foo’ was written with CL of QUORUM, the value for key ‘foo’ would go to nodes A and D.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/CASSANDRA-2434-data-inconsistency-figure-01.png\" width=\"530px\"/></p>\n<p>At a later point in time node B is resurrected and added back into the cluster. Around the same time a node C is added to the cluster and begins bootstrapping.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/CASSANDRA-2434-data-inconsistency-figure-02.png\" width=\"530px\"/></p>\n<p>One of the tokens node C calculates and acquires during the bootstrap process is for key ‘foo’. Node B is the closest node with data for the newly acquired token and thus node C begins streaming from the neighbouring node B. This process violates the consistency guarantees of Cassandra. This is because the data on node C will be the same as node B, and both are missing the value for key ‘foo’.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/CASSANDRA-2434-data-inconsistency-figure-03.png\" width=\"530px\"/></p>\n<p>Thus, a query with a CL of QUORUM may query nodes B and C and return no data which is incorrect, despite there being data for ‘foo’ on node A. Node D previously had the correct data, but it stopped being a replica after C was inserted into the cluster.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/CASSANDRA-2434-data-inconsistency-figure-04.png\" width=\"530px\"/></p>\n<p>The above issue was solved in <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2434\">CASSANDRA-2434</a> by changing the default behaviour to always trying to perform a consistent range movement. That is, when node C is added (in the previous example), data is streamed from the correct replica it is replacing, node D. In this case all queries with CL of QUORUM for the key ‘foo’ would always return the correct value.</p>\n<p>The JVM option <code class=\"highlighter-rouge\">cassandra.consistent.rangemovement</code> was added as part of this patch. The option allows consistent range movements during bootstrapping to be disabled should the user desire this behaviour. This fix is no silver bullet though, because it requires that the correct node be available for a consistent range moment during a bootstrap. This may not always be possible, and in such cases there are two options:</p>\n<ol><li>Get the required node back online (preferred option).</li>\n  <li>If the required node is unrecoverable, set <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.consistent.rangemovement=false\"</code> in the <em>cassandra-env.sh</em> file to perform inconsistent range movements when auto bootstrapping. Once bootstrapping is complete, a repair will need to be run using the following command on the node. This is to ensure the data it streamed is consistent with the rest of the replicas.</li>\n</ol><div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>nodetool repair -full\n</pre></div></div>\n<h2 id=\"adding-multiple-nodes\">Adding multiple nodes</h2>\n<p>Another common cause of grief for users was bootstrapping multiple node simultaneously; captured in <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-7069\">CASSANDRA-7069</a>. Adding two new nodes simultaneously to a cluster could potentially be harmful, given the operations performed by a new node when joining. Waiting two minutes for the gossip state to propagate before adding a new node is possible, however as noted in <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-9667\">CASSANDRA-9667</a>, there is no coordination between nodes during token selection. For example consider that case if Node A was bootstrapped, then two minutes later Node B was bootstrapped. Node B could potentially pick token ranges already selected by Node A.</p>\n<p>The above issue was solved in <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-7069\">CASSANDRA-7069</a> by changing the default behaviour such that adding a node would fail if another node was already bootstrapping in a cluster. Similar to <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2434\">CASSANDRA-2434</a>, this behaviour could be disabled by setting the JVM option <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.consistent.rangemovement=false\"</code> in the <em>cassandra-env.sh</em> file on the bootstrapping node. This means that if <code class=\"highlighter-rouge\">cassandra.consistent.rangemovement=false</code> is set to allow multiple nodes to bootstrap, the cluster runs the risk of violating consistency guarantees because of <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2434\">CASSANDRA-2434</a>.</p>\n<p>Changes made by <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-7069\">CASSANDRA-7069</a> mean that the default behaviour forces a user to add a single node at a time to expand the cluster. This is the safest way of adding nodes to expand a cluster and ensure that the correct amount of data is streamed between nodes.</p>\n<h2 id=\"data-streaming\">Data streaming</h2>\n<p>To further add to the confusion there is a misconception about what the <code class=\"highlighter-rouge\">auto_bootstrap</code> property does in relation to a node being added to the cluster. Despite its name, this property controls the data streaming step only in the bootstrap process. The boolean property is by default set to <strong>true</strong>. When set to <strong>true</strong>, the data streaming step will be performed during the bootstrap process.</p>\n<p>Setting <code class=\"highlighter-rouge\">auto_bootstrap</code> to <strong>false</strong> when bootstrapping a new node exposes the cluster to huge inconsistencies. This is because all the other steps in the process are carried out but no data is streamed to the node. Hence, the node would be in the <code class=\"highlighter-rouge\">UN</code> state without having any data for the token ranges it has been allocated! Furthermore, the new node without data will be serving reads and nodes that previously owned the tokens will no longer be serving reads. Effectively, the token ranges for that replica would be replaced with no data.</p>\n<p>It is worth noting that the other danger to using <code class=\"highlighter-rouge\">auto_bootstrap</code> set to <strong>false</strong> is no IP address collision check occurs. As per <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-10134\">CASSANDRA-10134</a>, if a new node has <code class=\"highlighter-rouge\">auto_bootstrap</code> set to <strong>false</strong> and has the same address as an existing down node, the new node will take over the token range of the old node. No error is thrown, only a warning messages such as the following one below is written to the logs of the <em>other</em> nodes in the cluster. At the time of writing this post, the fix for this issue only appears in Apache Cassandra version 3.6 and above.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>WARN  [GossipStage:1] 2017-05-19 17:35:10,994 TokenMetadata.java:237 - Changing /127.0.0.3's host ID from 1938db5d-5f23-46e8-921c-edde18e9c829 to c30fbbb8-07ae-412c-baea-90865856104e\n</pre></div></div>\n<p>The behaviour of <code class=\"highlighter-rouge\">auto_bootstrap: false</code> can lead to data inconsistencies in the following way. Consider the case of a cluster containing three nodes A, B and D with a RF of 3. If node B was offline and a key ‘foo’ was written with CL of QUORUM, the value for key ‘foo’ would go to nodes A and D. In this scenario Node D is the owner of the token relating to the key ‘foo’.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/auto-bootstrap-data-inconsistency-figure-01.png\" width=\"530px\"/></p>\n<p>At a later point in time node B is resurrected and added back into the cluster. Around the same time a node C is added to the cluster with <code class=\"highlighter-rouge\">auto_bootstrap</code> set to <strong>false</strong> and begins the joining process.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/auto-bootstrap-data-inconsistency-figure-02.png\" width=\"530px\"/></p>\n<p>One of the tokens node C calculates and acquires during the bootstrap process is for key ‘foo’. Now node D is no longer the owner and hence its data for the key ‘foo’ will no longer be used during reads/writes. This process causes inconsistencies in Cassandra because both nodes B and C contain no data for key ‘foo’.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/auto-bootstrap-data-inconsistency-figure-03.png\" width=\"530px\"/></p>\n<p>Thus, a query with a CL of QUORUM may query nodes B and C and return no data which is incorrect, despite there being data for ‘foo’ on node A. Node D previously had data, but it stopped being a replica after C was inserted.</p>\n<p><img src=\"http://thelastpickle.com/files/auto-bootstrapping/auto-bootstrap-data-inconsistency-figure-04.png\" width=\"530px\"/></p>\n<p>This confusing behaviour is one of the reasons why if you look into the <em>cassandra.yaml</em> file you will notice that the <code class=\"highlighter-rouge\">auto_bootstrap</code> configuration property is missing. Exposure of the property in the <em>cassandra.yaml</em> was short lived, as it was removed via <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-2447\">CASSANDRA-2447</a> in version 1.0.0. As a result, the property is hidden and its default value of <strong>true</strong> means that new nodes will stream data when they join the cluster.</p>\n<p>So far we have examined various options that control the bootstrapping default behaviour when a new node is added to a cluster. Adding a new node is just one case where bootstrapping is performed, what about the case of replacing a node in the cluster if one goes down?</p>\n<p>Should an existing node go down and needs to be replaced, the JVM option <code class=\"highlighter-rouge\">cassandra.replace_address</code> can be used. Note that this option is only available for Apache Cassandra versions 2.x.x and higher. This feature has been around for a while and <a href=\"https://blog.alteroot.org/articles/2014-03-12/replace-a-dead-node-in-cassandra.html\">blogged about</a> by other users in the past.</p>\n<p>As the name suggests, it effectively replaces a down or dead node in the cluster with a new node. It is because of this that replace address option should only be used if the node is in a Down and Normal state (represented by <strong><code class=\"highlighter-rouge\">DN</code></strong> in the <code class=\"highlighter-rouge\">nodetool status</code>). Furthermore, there are no range movements that occur when using this feature, the new replacement node will simply inherit the old dead node’s token ranges. This is simpler than decommissioning the dead node and bootstrapping a fresh one, which would involve two range movements and two streaming phases. Yuck! To use the option, simply add <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.replace_address=&lt;IP_ADDRESS&gt;\"</code> to the <em>cassandra-env.sh</em> file of the new node that will be replacing the old node. Where <code class=\"highlighter-rouge\">&lt;IP_ADDRESS&gt;</code> is the IP address of the node to be replaced.</p>\n<p>Once the node completes bootstrapping and joins the cluster, the <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.replace_address=&lt;IP_ADDRESS&gt;\"</code> option must be removed from the <em>cassandra-env.sh</em> file or the node will fail to start on a restart. This is a short coming of the <code class=\"highlighter-rouge\">cassandra.replace_address</code> feature. Many operators will typically be worried about a dead node being replaced and as a result forget to update the <em>cassandra-env.sh</em> file after the job is complete. It was for this reason that <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-7356\">CASSANDRA-7356</a> was raised and resulted in a new option being added; <code class=\"highlighter-rouge\">cassandra.replace_address_first_boot</code>. This option works once when Cassandra is first started and the replacement node inserted into the cluster. After that, the option is ignored for all subsequent restarts. It works in the same way as its predecessor; simply add <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.replace_address_first_boot=&lt;IP_ADDRESS&gt;\"</code> to the <em>cassandra-env.sh</em> and the new node is ready to be inserted.</p>\n<p>Ok, so you need to replace a seed node. Seed nodes are just like every other node in the cluster. As per the <a href=\"https://cassandra.apache.org/doc/latest/faq/index.html?highlight=seed#what-are-seeds\">Apache Cassandra documentation</a>, the only difference being seed nodes are the go to node when a new node joins the cluster.</p>\n<p>There are a few extra steps to replace a seed node and bootstrap a new one in its place. Before adding the replacement seed node, the IP address of the seed node will need to be removed from the <code class=\"highlighter-rouge\">seed_provider</code> list in the <em>cassandra.yaml</em> file and replaced with another node in the cluster. This needs to be done for all the nodes in the cluster. Naturally, a rolling restart will need to be performed for the changes to take effect. Once the change is complete the replacement node can be inserted as described in the previous section of this post.</p>\n<p>Once your node has successfully completed the bootstrapping process, it will transition to Up and Normal state (represented by <strong><code class=\"highlighter-rouge\">UN</code></strong> in the <code class=\"highlighter-rouge\">nodetool status</code>) to indicate it is now part of the cluster. At this point it is time to cleanup the nodes on your cluster. Yes, your nodes are dirty and need to be cleaned. “Why?” you ask, well the reason is the data that has been acquired by the newly added node still remains on the nodes that previously owned it. Whilst the nodes that previously owned the data have streamed it to the new node and relinquished the associated tokens, the data that was streamed still remains on the original nodes. This “orphaned” data is consuming valuable disk space, and in the cases large data sets; probably consuming a significant amount.</p>\n<p>However, before running off to the console to remove the orphaned data from the nodes, make sure it is done as a last step in a cluster expansion. If the expansion of the cluster requires only one node to be added, perform the cleanup after the node has successfully completed bootstrapping and joined the cluster. If the expansion requires three nodes to be added, perform the cleanup after all three nodes have successfully completed bootstrapping and joined the cluster. This is because the cleanup will need to be executed on all nodes in the cluster, except for the last node that was added to the cluster. The last node added to the cluster will contain only the data it needed for the tokens acquired, where as other nodes may contain data for tokens they no longer have. It is still ok to run cleanup on the last node, it will likely return immediately after it is called.</p>\n<p>The cleanup can be executed on each node using the following command.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>nodetool cleanup -j &lt;COMPACTION_SLOTS&gt;\n</pre></div></div>\n<p>Where\n <code class=\"highlighter-rouge\">&lt;COMPACTION_SLOTS&gt;</code> is the number of compaction slots to use for cleanup. By default this is <code class=\"highlighter-rouge\">2</code>. If set to <code class=\"highlighter-rouge\">0</code> it will use use all available compaction threads.</p>\n<p>It is probably worth limiting the number of compaction slots used by <code class=\"highlighter-rouge\">cleanup</code> otherwise it could potentially block compactions.</p>\n<p>The bootstrap process for a joining node can fail. Bootstrapping will put extra load on the network so should bootstrap fail, you could try tweaking the <code class=\"highlighter-rouge\">streaming_socket_timeout_in_ms</code>. Set <code class=\"highlighter-rouge\">streaming_socket_timeout_in_ms</code> in the <em>cassandra.yaml</em> file to 24 hours (60 * 60 * 24 * 1000 = 86,400,000ms). Having a socket timeout set is crucial for catching streams that hang and reporting them via an exception in the logs as per <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-11286\">CASSANDRA-11286</a>.</p>\n<p>If the bootstrap process fails in Cassandra version 2.1.x, the process will need to be restarted all over again. This can be done using the following steps.</p>\n<ol><li>Stop Cassandra on the node.</li>\n  <li>Delete all files and directories from the <em>data</em>, <em>commitlog</em> and <em>save_cache</em> directories but leave the directories there.</li>\n  <li>Wait about two minutes.</li>\n  <li>Start Cassandra on the node.</li>\n</ol><p>If the bootstrap process fails in Cassandra 2.2.x, the process can be easily be resumed using the following command thanks to <a href=\"https://issues.apache.org/jira/browse/CASSANDRA-8942\">CASSANDRA-8942</a>.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>nodetool bootstrap resume\n</pre></div></div>\n<p>We have gone through a lot of theory in this post, so I thought it would be good to test some of it out to demonstrate what can happen when bootstrapping multiple nodes at the same time.</p>\n<h2 id=\"setup\">Setup</h2>\n<p>In my test I used a three node local cluster running Apache Cassandra 2.1.14 which was created with the <a href=\"https://github.com/pcmanus/ccm\">ccm</a> tool. Each node was configured to use vnodes; specifically <code class=\"highlighter-rouge\">num_tokens</code> was set to <code class=\"highlighter-rouge\">32</code> in the <em>cassandra.yaml</em> file. The cluster was loaded with around 20 GB of data generated from the <a href=\"https://github.com/killrweather/killrweather\">killrweather</a> dataset. Data loading was performed in batches using <a href=\"https://github.com/rustyrazorblade/cdm\">cdm</a>. Prior to starting the test the cluster looked like this.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node1 nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  19.19 GB   32      29.1%             cfb50e13-52a4-4821-bca2-4dba6061d38a  rack1\nUN  127.0.0.2  9.55 GB    32      37.4%             5176598f-bbab-4165-8130-e33e39017f7e  rack1\nUN  127.0.0.3  19.22 GB   32      33.5%             d261faaf-628f-4b86-b60b-3825ed552aba  rack1\n</pre></div></div>\n<p>It was not the most well balanced cluster, however it was good enough for testing. It should be noted that the node with IP address <code class=\"highlighter-rouge\">127.0.0.1</code> was set to be the only seed node in the cluster. Taking a quick peak at the keyspace configuration in using CQLSH and we can see that it was using <code class=\"highlighter-rouge\">replication_factor: 1</code> i.e. <code class=\"highlighter-rouge\">RF = 1</code>.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>cqlsh&gt; describe killrweather\nCREATE KEYSPACE killrweather WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;\n</pre></div></div>\n<h2 id=\"adding-a-new-node\">Adding a new node</h2>\n<p>A new node (node4) was added to the cluster.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node4 start\n</pre></div></div>\n<p>After a minute or so node4 was in the <code class=\"highlighter-rouge\">UJ</code> state and began the bootstrap process.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node1 nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  19.19 GB   32      29.1%             cfb50e13-52a4-4821-bca2-4dba6061d38a  rack1\nUN  127.0.0.2  9.55 GB    32      37.4%             5176598f-bbab-4165-8130-e33e39017f7e  rack1\nUN  127.0.0.3  19.22 GB   32      33.5%             d261faaf-628f-4b86-b60b-3825ed552aba  rack1\nUJ  127.0.0.4  14.44 KB   32      ?                 ae0a26a6-fab5-4cab-a189-697818be3c95  rack1\n</pre></div></div>\n<p>It was observed that node4 had started streaming data from node1 (IP address <code class=\"highlighter-rouge\">127.0.0.1</code>) and node2 (IP address <code class=\"highlighter-rouge\">127.0.0.2</code>).</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node4 nodetool netstats\nMode: JOINING\nBootstrap f4e54a00-36d9-11e7-b18e-9d89ad20c2d3\n    /127.0.0.1\n        Receiving 9 files, 10258729018 bytes total. Already received 2 files, 459059994 bytes total\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-3-Data.db 452316846/452316846 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-2-Data.db 6743148/6743148 bytes(100%) received from idx:0/127.0.0.1\n    /127.0.0.3\n    /127.0.0.2\n        Receiving 11 files, 10176549820 bytes total. Already received 1 files, 55948069 bytes total\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\nRead Repair Statistics:\nAttempted: 0\nMismatch (Blocking): 0\nMismatch (Background): 0\nPool Name                    Active   Pending      Completed\nCommands                        n/a         0              6\nResponses                       n/a         0            471\n</pre></div></div>\n<h2 id=\"adding-another-new-node\">Adding another new node</h2>\n<p>A few minutes later another new node (node5) was added to the cluster. To add this node to the cluster while node4 was bootstrapping the JVM option <code class=\"highlighter-rouge\">JVM_OPTS=\"$JVM_OPTS -Dcassandra.consistent.rangemovement=false\"</code> was added to the node’s <em>cassandra-env.sh</em> file. The node was then started.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node5 start\n</pre></div></div>\n<p>After about a minute node5 was in the <code class=\"highlighter-rouge\">UJ</code> state and it too began the bootstrap process.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node1 nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  19.19 GB   32      29.1%             cfb50e13-52a4-4821-bca2-4dba6061d38a  rack1\nUN  127.0.0.2  9.55 GB    32      37.4%             5176598f-bbab-4165-8130-e33e39017f7e  rack1\nUN  127.0.0.3  19.22 GB   32      33.5%             d261faaf-628f-4b86-b60b-3825ed552aba  rack1\nUJ  127.0.0.4  106.52 KB  32      ?                 ae0a26a6-fab5-4cab-a189-697818be3c95  rack1\nUJ  127.0.0.5  14.43 KB   32      ?                 a71ed178-f353-42ec-82c8-d2b03967753a  rack1\n</pre></div></div>\n<p>It was observed that node5 had started streaming data from node2 as well; the same node that node4 was streaming data from.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node5 nodetool netstats\nMode: JOINING\nBootstrap 604b5690-36da-11e7-aeb6-9d89ad20c2d3\n    /127.0.0.3\n    /127.0.0.2\n        Receiving 11 files, 10176549820 bytes total. Already received 1 files, 55948069 bytes total\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\n    /127.0.0.1\nRead Repair Statistics:\nAttempted: 0\nMismatch (Blocking): 0\nMismatch (Background): 0\nPool Name                    Active   Pending      Completed\nCommands                        n/a         0              8\nResponses                       n/a         0            255\n</pre></div></div>\n<p>The interesting point to note when looking at the <code class=\"highlighter-rouge\">netstats</code> was that both node4 and node5 were each streaming a <em>Data.db</em> file exactly <code class=\"highlighter-rouge\">55948069</code> bytes from node2.</p>\n<h2 id=\"data-streaming-much\">Data streaming much</h2>\n<p>It had appeared that both node4 and node5 were streaming the same data from node2. This continued as the bootstrapping process progressed; the size of the files being streamed from node2 were the same for both node4 and node5. Checking the <code class=\"highlighter-rouge\">netstats</code> on node4 produced the following.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node4 nodetool netstats\nBootstrap f4e54a00-36d9-11e7-b18e-9d89ad20c2d3\n    /127.0.0.1\n        Receiving 9 files, 10258729018 bytes total. Already received 6 files, 10112487796 bytes total\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-13-Data.db 1788940555/1788940555 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-5-Data.db 7384377358/7384377358 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-12-Data.db 27960312/27960312 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-3-Data.db 452316846/452316846 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-11-Data.db 452149577/452149577 bytes(100%) received from idx:0/127.0.0.1\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-2-Data.db 6743148/6743148 bytes(100%) received from idx:0/127.0.0.1\n    /127.0.0.3\n    /127.0.0.2\n        Receiving 11 files, 10176549820 bytes total. Already received 10 files, 10162463079 bytes total\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-9-Data.db 55590043/55590043 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-6-Data.db 901588743/901588743 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-15-Data.db 14081154/14081154 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-16-Data.db 1450179/1450179 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-8-Data.db 901334951/901334951 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-10-Data.db 3622476547/3622476547 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-17-Data.db 56277615/56277615 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-4-Data.db 3651310715/3651310715 bytes(100%) received from idx:0/127.0.0.2\n            .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-7-Data.db 902405063/902405063 bytes(100%) received from idx:0/127.0.0.2\nRead Repair Statistics:\nAttempted: 0\nMismatch (Blocking): 0\nMismatch (Background): 0\nPool Name                    Active   Pending      Completed\nCommands                        n/a         0              6\nResponses                       n/a         0           4536\n</pre></div></div>\n<p>Then checking <code class=\"highlighter-rouge\">netstats</code> on node5 produced the following.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node5 nodetool netstats\nMode: JOINING\nBootstrap 604b5690-36da-11e7-aeb6-9d89ad20c2d3\n    /127.0.0.1\n    /127.0.0.3\n    /127.0.0.2\n        Receiving 11 files, 10176549820 bytes total. Already received 9 files, 10106185464 bytes total\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-2-Data.db 3651310715/3651310715 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-9-Data.db 1450179/1450179 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-3-Data.db 901588743/901588743 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-6-Data.db 55590043/55590043 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-4-Data.db 902405063/902405063 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-8-Data.db 14081154/14081154 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-5-Data.db 901334951/901334951 bytes(100%) received from idx:0/127.0.0.2\n            .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-7-Data.db 3622476547/3622476547 bytes(100%) received from idx:0/127.0.0.2\nRead Repair Statistics:\nAttempted: 0\nMismatch (Blocking): 0\nMismatch (Background): 0\nPool Name                    Active   Pending      Completed\nCommands                        n/a         0              8\nResponses                       n/a         0           4383\n</pre></div></div>\n<p>To be absolutely sure about what was being observed, I ran a command to order the <code class=\"highlighter-rouge\">netstats</code> output by file size for both node4 and node5.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ for file_size in $(ccm node4 nodetool netstats  | grep '(100%)\\ received' | grep '127.0.0.2' | tr -s ' ' | cut -d' ' -f3 | cut -d'/' -f1 | sort -g); do ccm node4 nodetool netstats | grep ${file_size} | tr -s ' '; done\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-16-Data.db 1450179/1450179 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-15-Data.db 14081154/14081154 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-9-Data.db 55590043/55590043 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-17-Data.db 56277615/56277615 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-8-Data.db 901334951/901334951 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-6-Data.db 901588743/901588743 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-7-Data.db 902405063/902405063 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-10-Data.db 3622476547/3622476547 bytes(100%) received from idx:0/127.0.0.2\n .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-4-Data.db 3651310715/3651310715 bytes(100%) received from idx:0/127.0.0.2\n$ for file_size in $(ccm node5 nodetool netstats  | grep '(100%)\\ received' | grep '127.0.0.2' | tr -s ' ' | cut -d' ' -f3 | cut -d'/' -f1 | sort -g); do ccm node5 nodetool netstats | grep ${file_size} | tr -s ' '; done\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-9-Data.db 1450179/1450179 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-8-Data.db 14081154/14081154 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-6-Data.db 55590043/55590043 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-1-Data.db 55948069/55948069 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-5-Data.db 901334951/901334951 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-3-Data.db 901588743/901588743 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-4-Data.db 902405063/902405063 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-7-Data.db 3622476547/3622476547 bytes(100%) received from idx:0/127.0.0.2\n .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-tmp-ka-2-Data.db 3651310715/3651310715 bytes(100%) received from idx:0/127.0.0.2\n</pre></div></div>\n<p>With the exception of one file being streamed by node4, <em>killrweather-raw_weather_data-tmp-ka-17-Data.db</em> (size 56277615 bytes), node4 and node5 looked to be streaming the same data from node2. This was the first confirmation that node5 had stolen the tokens that where originally calculated by node4. Furthermore, it looked like node 4 was performing unnecessary streaming from node2. I noted down the file sizes displayed by node5’s <code class=\"highlighter-rouge\">netstats</code> output to help track down data files on each node.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node5 nodetool netstats | grep '(100%)\\ received' | grep '127.0.0.2' | tr -s ' ' | cut -d' ' -f3 | cut -d'/' -f1 | sort -g &gt; file_sizes.txt; cat file_sizes.txt\n1450179\n14081154\n55590043\n55948069\n901334951\n901588743\n902405063\n3622476547\n3651310715\n</pre></div></div>\n<h2 id=\"token-and-the-thief\">Token and the thief</h2>\n<p>Once both nodes had finished bootstrapping and had successfully joined the cluster it looked like this.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node1 nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  19.19 GB   32      14.8%             cfb50e13-52a4-4821-bca2-4dba6061d38a  rack1\nUN  127.0.0.2  9.55 GB    32      22.0%             5176598f-bbab-4165-8130-e33e39017f7e  rack1\nUN  127.0.0.3  19.22 GB   32      23.6%             d261faaf-628f-4b86-b60b-3825ed552aba  rack1\nUN  127.0.0.4  19.17 GB   32      17.5%             ae0a26a6-fab5-4cab-a189-697818be3c95  rack1\nUN  127.0.0.5  9.55 GB    32      22.1%             a71ed178-f353-42ec-82c8-d2b03967753a  rack1\n</pre></div></div>\n<p>Using the file sizes I captured earlier from node5 <code class=\"highlighter-rouge\">netstats</code>, I checked the data directories of node4 and node5 to confirm both nodes contained files of those sizes.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ for file_size in $(cat file_sizes.txt); do ls -al .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/ | grep ${file_size}; done\n-rw-r--r--    1 anthony  staff     1450179 12 May 16:33 killrweather-raw_weather_data-ka-16-Data.db\n-rw-r--r--    1 anthony  staff    14081154 12 May 16:33 killrweather-raw_weather_data-ka-15-Data.db\n-rw-r--r--    1 anthony  staff    55590043 12 May 16:33 killrweather-raw_weather_data-ka-9-Data.db\n-rw-r--r--    1 anthony  staff    55948069 12 May 16:33 killrweather-raw_weather_data-ka-1-Data.db\n-rw-r--r--    1 anthony  staff   901334951 12 May 16:33 killrweather-raw_weather_data-ka-8-Data.db\n-rw-r--r--    1 anthony  staff   901588743 12 May 16:33 killrweather-raw_weather_data-ka-6-Data.db\n-rw-r--r--    1 anthony  staff   902405063 12 May 16:33 killrweather-raw_weather_data-ka-7-Data.db\n-rw-r--r--    1 anthony  staff  3622476547 12 May 16:33 killrweather-raw_weather_data-ka-10-Data.db\n-rw-r--r--    1 anthony  staff  3651310715 12 May 16:33 killrweather-raw_weather_data-ka-4-Data.db\n$ for file_size in $(cat file_sizes.txt); do ls -al  .../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/ | grep ${file_size}; done\n-rw-r--r--    1 anthony  staff     1450179 12 May 16:36 killrweather-raw_weather_data-ka-9-Data.db\n-rw-r--r--    1 anthony  staff    14081154 12 May 16:36 killrweather-raw_weather_data-ka-8-Data.db\n-rw-r--r--    1 anthony  staff    55590043 12 May 16:36 killrweather-raw_weather_data-ka-6-Data.db\n-rw-r--r--    1 anthony  staff    55948069 12 May 16:36 killrweather-raw_weather_data-ka-1-Data.db\n-rw-r--r--    1 anthony  staff   901334951 12 May 16:36 killrweather-raw_weather_data-ka-5-Data.db\n-rw-r--r--    1 anthony  staff   901588743 12 May 16:36 killrweather-raw_weather_data-ka-3-Data.db\n-rw-r--r--    1 anthony  staff   902405063 12 May 16:36 killrweather-raw_weather_data-ka-4-Data.db\n-rw-r--r--    1 anthony  staff  3622476547 12 May 16:36 killrweather-raw_weather_data-ka-7-Data.db\n-rw-r--r--    1 anthony  staff  3651310715 12 May 16:36 killrweather-raw_weather_data-ka-2-Data.db\n</pre></div></div>\n<p>So both nodes contained files of the same size. I then decided to check if the files on each node that were the same size had the same data content. This check was done by performing an MD5 check of file pairs that were the same size.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ BASE_DIR=...; DATA_DIR=data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d; for file_size in $(cat file_sizes.txt); do node_4_file=$(ls -al ${BASE_DIR}/node4/${DATA_DIR}/ | grep ${file_size} | tr -s ' ' | cut -d' ' -f9); node_5_file=$(ls -al ${BASE_DIR}/node5/${DATA_DIR}/ | grep ${file_size} | tr -s ' ' | cut -d' ' -f9); md5 ${BASE_DIR}/node4/${DATA_DIR}/${node_4_file} ${BASE_DIR}/node5/${DATA_DIR}/${node_5_file}; echo; done\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-16-Data.db) = a9edb85f70197c7f37aa021c817de2a2\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-9-Data.db) = a9edb85f70197c7f37aa021c817de2a2\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-15-Data.db) = 975f184ae36cbab07a9c28b032532f88\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-8-Data.db) = 975f184ae36cbab07a9c28b032532f88\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-9-Data.db) = f0160cf8e7555031b6e0835951e1896a\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-6-Data.db) = f0160cf8e7555031b6e0835951e1896a\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-1-Data.db) = 7789b794bb3ef24338282d4a1a960903\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-1-Data.db) = 7789b794bb3ef24338282d4a1a960903\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-8-Data.db) = 1738695bb6b4bd237b3592e80eb785f2\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-5-Data.db) = 1738695bb6b4bd237b3592e80eb785f2\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-6-Data.db) = f7d1faa5c59a26a260038d61e4983022\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-3-Data.db) = f7d1faa5c59a26a260038d61e4983022\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-7-Data.db) = d791179432dcdbaf9a9b315178fb04c7\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-4-Data.db) = d791179432dcdbaf9a9b315178fb04c7\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-10-Data.db) = 3e6623c2f06bcd3f5caeacee1917898b\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-7-Data.db) = 3e6623c2f06bcd3f5caeacee1917898b\nMD5 (.../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-4-Data.db) = 8775f5df08882df353427753f946bf10\nMD5 (.../node5/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-2-Data.db) = 8775f5df08882df353427753f946bf10\n</pre></div></div>\n<p>Now I had absolute proof that both nodes did in fact stream the same data from node2. It did look as though that when node5 joined the cluster it had taken tokens calculated by node4. If this were the case, it would mean that the data files on node4 that are the same on node5 would no longer be needed. One way to prove that there is “orphaned” data on node4 i.e. data not associated to any of node4’s tokens, would be to run <code class=\"highlighter-rouge\">cleanup</code> on the cluster. If there is orphaned data on node4 the cleanup would technically delete all or some of those files. Before running cleanup on the cluster, I took note of the files on node4 which were the same as the ones on node5.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ for file_size in $(cat file_sizes.txt); do ls -al .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/ | grep ${file_size}; | tr -s ' ' | cut -d' '  -f9; done &gt; node4_orphaned_files.txt; cat node4_orphaned_files.txt\nkillrweather-raw_weather_data-ka-16-Data.db\nkillrweather-raw_weather_data-ka-15-Data.db\nkillrweather-raw_weather_data-ka-9-Data.db\nkillrweather-raw_weather_data-ka-1-Data.db\nkillrweather-raw_weather_data-ka-8-Data.db\nkillrweather-raw_weather_data-ka-6-Data.db\nkillrweather-raw_weather_data-ka-7-Data.db\nkillrweather-raw_weather_data-ka-10-Data.db\nkillrweather-raw_weather_data-ka-4-Data.db\n</pre></div></div>\n<p>I then ran a <code class=\"highlighter-rouge\">cleanup</code> on all the nodes in the cluster.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ ccm node1 nodetool cleanup\n$ ccm node2 nodetool cleanup\n$ ccm node3 nodetool cleanup\n$ ccm node4 nodetool cleanup\n$ ccm node5 nodetool cleanup\n$ ccm node1 nodetool status\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  9.57 GB    32      14.8%             cfb50e13-52a4-4821-bca2-4dba6061d38a  rack1\nUN  127.0.0.2  138.92 KB  32      22.0%             5176598f-bbab-4165-8130-e33e39017f7e  rack1\nUN  127.0.0.3  19.22 GB   32      23.6%             d261faaf-628f-4b86-b60b-3825ed552aba  rack1\nUN  127.0.0.4  9.62 GB    32      17.5%             ae0a26a6-fab5-4cab-a189-697818be3c95  rack1\nUN  127.0.0.5  9.55 GB    32      22.1%             a71ed178-f353-42ec-82c8-d2b03967753a  rack1\n</pre></div></div>\n<p>From this output it was obvious that node4 contained orphaned data. Earlier I had run a <code class=\"highlighter-rouge\">nodetool status</code> which was just after both nodes completed bootstrapping and moved to the <code class=\"highlighter-rouge\">UN</code> state, and prior to running <code class=\"highlighter-rouge\">cleanup</code>. The output produced at that point showed that node4 had a <em>Load</em> of <code class=\"highlighter-rouge\">19.17 GB</code>. Now after cleanup it was showing to have a load of <code class=\"highlighter-rouge\">9.62 GB</code>. As a final verification, I iterated through the list of files on node4 which were the same as the ones on node5 (<em>node4_orphaned_files.txt</em>) and checked if they still were present on node4.</p>\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre>$ for file_name in $(cat node4_orphaned_files.txt); do ls .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/${file_name}; done\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-16-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-15-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-9-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-1-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-8-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-6-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-7-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-10-Data.db: No such file or directory\nls: .../node4/data0/killrweather/raw_weather_data-32f23d1015cb11e79d0fa90042a0802d/killrweather-raw_weather_data-ka-4-Data.db: No such file or directory\n</pre></div></div>\n<p>As it can be seen the files were deleted as part of the cleanup on node4. Which means that during bootstrap node4 originally calculated tokens for that data. It then asked for a list of files that related to those tokens from node2 and began streaming them. A little while later node5 was added to the cluster while node4 was still bootstrapping. It then calculated tokens that overlapped with node4’s tokens. Node5 then asked for a list of files that related to those tokens from node2 and started streaming data for them as well. The issue here is node4 was never notified that it no longer required to stream files from node2. Hence, unnecessary resources were being consumed as a result of bootstrapping two nodes at the same time.</p>\n<p>Auto bootstrapping combined with vnodes is probably one of the most handy features in Cassandra. It takes the pain out of manually having to move data around ensure a continuous availability while expanding the cluster in a reliable and efficient way. There a number of knobs and levers for controlling the default behaviour of bootstrapping.</p>\n<h2 id=\"configuration-properties\">Configuration properties</h2>\n<ul><li><code class=\"highlighter-rouge\">auto_bootstrap</code> - controls whether data is streamed to the new node when inserted.</li>\n  <li><code class=\"highlighter-rouge\">streaming_socket_timeout_in_ms</code> - sets socket timeout for streaming operations.</li>\n</ul><h2 id=\"jvm-options\">JVM options</h2>\n<ul><li><code class=\"highlighter-rouge\">cassandra.consistent.rangemovement</code> - controls consistent range movements and multiple node bootstrapping.</li>\n  <li><code class=\"highlighter-rouge\">cassandra.replace_address_first_boot=&lt;IP_ADDRESS&gt;</code> - allows a down node to be replaced with a new node.</li>\n</ul><p>As demonstrated by setting the JVM option <code class=\"highlighter-rouge\">cassandra.consistent.rangemovement=false</code> the cluster runs the risk of over streaming of data and worse still, it can violate consistency. For new users to Cassandra, the safest way to add multiple nodes into a cluster is to add them one at a time. Stay tuned as I will be following up with another post on bootstrapping.</p>"}}]}},"pageContext":{"alternative_id":5115}}