{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Read CSV File in Spark and Write it to Cassandra","alternative_id":9070,"content":"<div class=\"vote\"><h3>Vote count:&#13;\n        &#13;\n        1&#13;\n        &#13;\n&#13;\n        &#13;\n        &#13;\n&#13;\n&#13;\n</h3></div><div class=\"post-text\" itemprop=\"text\">&#13;\n&#13;\n<p>I am trying to read a CVS File with Spark and then save it to Cassandra. Saving to Cassandra is working, when I'm using trivial values.</p>\n<p>I have a file with the following values:</p>\n<p><code>id,name,tag1|tag2|tag3</code></p>\n<p>I want to store it in a cassandra table: </p>\n<p><code>id bigint, name varchar, tags set</code></p>\n<p>I defined a case class for this:</p>\n<p><code>case class Item(id:Integer,name:String,tag:Set[String])</code></p>\n<p>Then I use this expression for getting the RDD out of the CVS file</p>\n<p><code>val items = sc.textFile(\"items.csv\").map(l =&gt; l.split(\",\") match {case Array (a,b,c) =&gt; Item(Integer.parseInt(a),b,c.split(\"\\\\|\").toSet)})</code></p>\n<p>When I now call <code>collect</code> or <code>saveToCassandra</code> on items (which starts the processing) I get the following error:</p>\n<p><code>org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 29.0 failed 1 times, most recent failure: Lost task 1.0 in stage 29.0 (TID 38, localhost): scala.MatchError: [Ljava.lang.String;@6030bbe6 (of class [Ljava.lang.String;)\n    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2.apply(&lt;console&gt;:33)\n    at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2.apply(&lt;console&gt;:33)\n    at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n    at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:249)\n    at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:172)\n    at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:79)\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:242)\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)\n    at org.apache.spark.scheduler.Task.run(Task.scala:64)\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n</code></p></div><div class=\"user-action-time\">&#13;\n        <a href=\"https://stackoverflow.com/posts/29966951/revisions\" title=\"show all edits to this post\">edited Apr 30 '15 at 12:15</a>&#13;</div><div class=\"user-details\">&#13;\n        &#13;\n        &#13;</div><div class=\"user-action-time\">&#13;\n        asked Apr 30 '15 at 11:48&#13;</div><div class=\"user-details\">&#13;\n        <a href=\"https://stackoverflow.com/users/4203061/mniehoff\">mniehoff</a>&#13;\n        <div class=\"-flair\">&#13;\n            2191213&#13;\n        </div>&#13;</div><h2 data-answercount=\"2\">&#13;\n                                2 Answers&#13;\n                                2&#13;</h2><div class=\"vote\"><h3>Vote count:&#13;\n        &#13;\n        2&#13;\n        &#13;\n&#13;\n&#13;\n&#13;\n        accepted&#13;\n&#13;\n</h3></div><div class=\"post-text\" itemprop=\"text\">&#13;\n<p>As mentioned, the issue is that splitting on some inputs is generating an array that has less or more than the 3 elements used in the match.  </p>\n<p>But the <code>partialFuntion</code> used to do the match can be used to filter on the elements that <em>do</em> fit the match criteria. <code>rdd.collect{partialFunction}</code> is exactly meant for that:</p>\n<pre>val data = sc.textFile(\"items.csv\")\nval arrayData = data.map(l =&gt; l.split(\",\"))\nval items = arrayData.collect{case Array (a,b,c) =&gt; Item(Integer.parseInt(a),b,c.split(\"\\\\|\").toSet)})\n items.saveToCassandra(...)\n</pre>\n<ul><li>Note1: you should also protect against dirty values. e.g. parseInt on a value that's not an int number,...) </li>\n<li>Note2: <code>rdd.collect{partialFunc}</code> (filters/map data using a partial function) should not be confused with <code>rdd.collect</code> (get back data to the driver))</li>\n</ul></div><div class=\"user-action-time\">&#13;\n        answered Apr 30 '15 at 14:57&#13;</div><div class=\"user-details\">&#13;\n        <a href=\"https://stackoverflow.com/users/764040/maasg\">maasg</a>&#13;\n        <div class=\"-flair\">&#13;\n            27.4k76093&#13;\n        </div>&#13;</div><div class=\"vote\"><h3>Vote count:&#13;\n        &#13;\n        1&#13;\n        &#13;\n&#13;\n&#13;\n&#13;\n&#13;\n</h3></div><div class=\"post-text\" itemprop=\"text\">&#13;\n<p>You'll get that match error if your input <em>isn't</em> an array of 3 entries e.g.</p>\n<pre>String(\"a,b\").split(\",\") match {\n   case Array(a,b,c) =&gt; ....\n}\n</pre>\n<p>so I suspect this is some input data issue, and you need to cater for it in your <code>match</code>.</p></div><div class=\"user-action-time\">&#13;\n        answered Apr 30 '15 at 11:55&#13;</div><div class=\"user-details\">&#13;\n        <a href=\"https://stackoverflow.com/users/12960/brian-agnew\">Brian Agnew</a>&#13;\n        <div class=\"-flair\">&#13;\n            211k25262371&#13;\n        </div>&#13;</div>"}}]}},"pageContext":{"alternative_id":9070}}