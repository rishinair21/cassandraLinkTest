{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Apache Kafka Connect Architecture Overview - Instaclustr","alternative_id":12170,"content":"<p><a href=\"https://kafka.apache.org/documentation/#connect\">Kafka Connect</a> is an API and ecosystem of 3rd party connectors that enables <a href=\"https://www.instaclustr.com/solutions/managed-apache-kafka/\">Apache Kafka</a> to be scalable, reliable, and easily integrated with other heterogeneous systems (such as Cassandra, Spark, and Elassandra) without having to write any extra code. This blog is an overview of the main Kafka Connect components and their relationships. We’ll cover Source and Sink Connectors; Connectors, Plugins, Tasks and Workers; Clusters; and Converters.</p><p>For an example of how to use Kafka Connect see <strong><a href=\"https://www.instaclustr.com/apache-kafka/\">Apache Kafka</a> “Kongo” Part <a href=\"https://www.instaclustr.com/apache-kafka-kongo-part-4-1-connecting-kafka-to-cassandra-with-kafka-connect\">4.1</a> and <a href=\"https://www.instaclustr.com/apache-kafka-kongo-part-4-2-connecting-kafka-to-cassandra-with-kafka-connect\">4.2</a>: Connecting Kafka to Cassandra with Kafka Connect.</strong></p><p>At a high level, “Source connectors” pull data from an external system (the Source) and write it to <a href=\"https://www.instaclustr.com/solutions/managed-apache-kafka/\">Kafka</a> topics. “Sink connectors” read data from <a href=\"https://www.instaclustr.com/solutions/managed-apache-kafka/\">Kafka</a> topics and push it to an external system (the Sink). Each connector flavour is unidirectional, you can’t go against the flow. Here’s a simple diagram showing the high level Kafka Connect architecture with Source (green) and Sink (blue) data flows:</p><p><a href=\"https://www.instaclustr.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1.png\"><img class=\"aligncenter size-full wp-image-9503\" src=\"https://www.instaclustr.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1.png\" alt=\"\" width=\"2896\" height=\"1725\" srcset=\"https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1.png 2896w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-300x179.png 300w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-768x457.png 768w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-1024x610.png 1024w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-1200x715.png 1200w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-966x575.png 966w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-640x381.png 640w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-81x48.png 81w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/Kafka-Connect-Architecture-diagram-1-181x108.png 181w\" /></a>High Level Kafka Connect Architecture showing Source and Sink Flows</p><p>There are three main components to the Kafka Connect API, each with a different role: Connectors, Tasks and Workers. </p><p>Connectors are either <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/source/SourceConnector.html\">Source</a> or <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/sink/SinkConnector.html\">Sink</a> Connectors, and are responsible for a some of the Task management, but not the actual data movement.</p><p>Tasks come in two corresponding flavours as well, <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/source/SourceTask.html\">Source</a> and <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/sink/SinkTask.html\">Sink</a> Tasks. A Source Task will contain custom code to get data from the Source system (in the pull() method) and uses a Kafka producer which sends the data to Kafka topics. A Sink Task uses a Kafka consumer to poll Kafka topics and read data, and custom code to push data to the Sink system (in the put() method). Each Sink Task has a thread, and they belong to the same consumer group for <a href=\"https://www.instaclustr.com/exploring-apache-kafka-castle-architecture-semantics/\">load balancing</a>. </p><p>The components work together like this (with inspiration from <a href=\"http://shop.oreilly.com/product/0636920044123.do\">“Kafka: The Definitive Guide”</a>):</p><p><b>Connector “Plugins” (Collections of Connectors and Tasks)</b></p><p>A Connector <i>Plugin</i> is a collection of Connectors and Tasks deployed to each Worker.</p><p><b>Connector</b></p><p>Connectors are responsible for the number of tasks, splitting work between tasks, getting configurations for the tasks from the workers and passing it to the Tasks. E.g. to decide how many tasks to run for a Sink, a Connector could use the minimum of max.tasks set in the configuration and the number of partitions of the Kafka topic it is reading from). The workers actually start the Tasks.</p><p><b>Tasks</b></p><p>Tasks are responsible for getting data into and out of Kafka (but only on the Source or Sink side, the Workers manage data flow to/from Kafka topics). Once started, Source Tasks poll Source systems and get the data that the Workers send to Kafka topics, and Sink Tasks get records from Kafka via the Worker, and write the records to the Sink system.</p><p><b>Workers</b></p><p>Workers are the <i>processes</i> that execute the Connectors and Tasks. They handle the REST requests that define connectors and configurations, start the connectors and tasks and pass configurations to them. If using <i>distributed workers</i>, and a worker process dies, then the connectors and tasks associated with the failed worked will be taken over and load balanced among the remaining workers.</p><p>A Kafka Connect Cluster has one (<i>standalone</i>) or more (<i>distributed</i>) Workers running on one or multiple servers, and the Workers manage Connectors and Tasks, distributing work among the available Worker processes. Note that Kafka Connect does not automatically handle restarting or scaling of Workers, so this must be handled with some other solution.</p><p>The following diagram shows the main relationships and functions of each component in a connect cluster. A Kafka connect cluster can be run on one or more servers (for production these will be separate to the servers that the Kafka Brokers are running on), and one (but potentially more) workers on each server. Data movement is shown with green lines:</p><p><a href=\"https://www.instaclustr.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2.png\"><img class=\"aligncenter size-full wp-image-9521\" src=\"https://www.instaclustr.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2.png\" alt=\"\" width=\"3510\" height=\"2185\" srcset=\"https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2.png 3510w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-300x187.png 300w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-768x478.png 768w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-1024x637.png 1024w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-1200x747.png 1200w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-966x601.png 966w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-640x398.png 640w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-77x48.png 77w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-2-173x108.png 173w\" /></a></p><p>Apache Kafka Connect Architecture UML Diagram</p><p><img class=\"aligncenter size-full wp-image-9523\" src=\"https://www.instaclustr.com/wp-content/uploads/2018/05/pasted-image-0-1.png\" alt=\"\" width=\"548\" height=\"405\" srcset=\"https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pasted-image-0-1.png 548w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pasted-image-0-1-300x222.png 300w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pasted-image-0-1-65x48.png 65w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pasted-image-0-1-146x108.png 146w\" /></p><p>Just like Catalytic Converters for cars, <i>converters</i> are also a key part of the Kafka connector pipeline! I initially found converters perplexing as Kafka consumers and producers already have (De-)Serializers. Are converters the same or different?  Kafka doesn’t know anything about the data format of topic keys and value, it just treats them as byte arrays. So consumers and producers need to be able to convert objects to and from byte arrays, and that’s exactly what the (De-)Serializers do.</p><p>Doing some more research on Converters I found that the <a href=\"https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/storage/Converter.html\">converter interface docs say</a>: </p><blockquote> <p>“The Converter interface provides support for translating between Kafka Connect’s runtime data format and byte. Internally, this likely includes an intermediate step to the format used by the serialization layer.”</p> </blockquote><p>I also found that Converter has <code>fromConnectData()</code> and <code>toConnectData()</code> method that must be implemented for converting byte arrays to/from <i>Kafka Connect Data Objects</i>.  Connect “Data Objects” have <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/data/SchemaAndValue.html\">schemas and values</a>, and a <a href=\"https://kafka.apache.org/0110/javadoc/org/apache/kafka/connect/data/SchemaBuilder.html\">SchemaBuilder</a> which provides a fluent API for constructing Schema objects. Schemas are optional to support cases with schema-free data. <a href=\"https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/connector/ConnectRecord.html\">ConnectRecords</a> (subclasses SinkRecord and SourceRecord) are analogous to Kafka’s ConsumerRecord and ProducerRecord classes, and contain the data read from or written to Kafka. </p><p>In conclusion, here’s how Sources, Tasks, Converters, Topics, (De-)Serializers and Sinks fit together to give a complete end-to-end Kafka data pipeline:</p><p><a href=\"https://www.instaclustr.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e.png\"><img class=\"aligncenter size-full wp-image-9525\" src=\"https://www.instaclustr.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e.png\" alt=\"\" width=\"2731\" height=\"1876\" srcset=\"https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e.png 2731w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-300x206.png 300w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-768x528.png 768w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-1024x703.png 1024w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-1200x824.png 1200w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-897x616.png 897w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-640x440.png 640w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-70x48.png 70w, https://24b4dt1v60e526bo2p349l4c-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/Kafka-Connect-Architecture-diagram-3e-157x108.png 157w\" /></a></p><p>Complete end-to-end Kafka Data Pipeline</p><p>Finally, one nice feature of the Kafka Connect architecture is that because converters are decoupled from connectors, you can reuse any Kafka Connect Converter with any Kafka Connect Connector.</p><aside class=\"content-cta\"><div class=\"primary\"><p>Related Articles:</p></div></aside>"}}]}},"pageContext":{"alternative_id":12170}}