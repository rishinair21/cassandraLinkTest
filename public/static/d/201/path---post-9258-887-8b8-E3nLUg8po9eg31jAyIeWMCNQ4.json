{"data":{"allAnantCassandralinks":{"edges":[{"node":{"title":"Monitoring Cassandra garbage collector","alternative_id":9258,"content":"<section class=\"section section--body section--first\"><div class=\"section-divider\"><hr class=\"section-divider\" /></div><div class=\"section-content\"><div class=\"section-inner sectionLayout--insetColumn\"><figure id=\"c4a2\" class=\"graf graf--figure graf--leading\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*8uxzqct_Xvj5hzFqG3N0Rw.png\" data-width=\"716\" data-height=\"292\" data-action=\"zoom\" data-action-value=\"1*8uxzqct_Xvj5hzFqG3N0Rw.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*8uxzqct_Xvj5hzFqG3N0Rw.png\" alt=\"image\" /></div></div></figure><h1 id=\"ea01\" class=\"graf graf--h3 graf-after--figure graf--title\">Monitoring Cassandra garbage collector</h1><p id=\"2ff6\" class=\"graf graf--p graf-after--h3 graf--trailing\">Having database hiccups is the last thing you want on production. Very common cause of misbehaving nodes are long GC pauses — while running f.ex. full GC node doesn’t handle requests and if cycle is long enough then requests will timeout. I’ll describe how we monitor garbage collector in Cassandra clusters used by <a href=\"http://www.opera.com/computer/features/sync\" data-href=\"http://www.opera.com/computer/features/sync\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">Opera sync</a> so you can easily see affected nodes, spot patterns which are great help while debugging issues or tuning configuration.</p></div></div></section><section class=\"section section--body\"><div class=\"section-divider\"><hr class=\"section-divider\" /></div><div class=\"section-content\"><div class=\"section-inner sectionLayout--insetColumn\"><p id=\"55c7\" class=\"graf graf--p graf--leading\">You can configure C* to output GC logs to dedicated file through <em class=\"markup--em markup--p-em\">cassandra-env.sh</em>. Edit this file and uncomment:</p><pre id=\"2093\" class=\"graf graf--pre graf-after--p\">JVM_OPTS=\"$JVM_OPTS -XX:+PrintGCDateStamps\"<br />JVM_OPTS=\"$JVM_OPTS -Xloggc:/var/log/cassandra/gc.log\"</pre><p id=\"6915\" class=\"graf graf--p graf-after--pre\">When done C* needs to be restarted. Soon after restart you should see in <em class=\"markup--em markup--p-em\">gc.log</em> entries like:</p><pre id=\"72c1\" class=\"graf graf--pre graf-after--p\">2015–12–07T09:52:01.159+0000: 247122.436: [GC 6496818K-&gt;4840023K(8178944K), 0.0380030 secs]</pre><p id=\"3fca\" class=\"graf graf--p graf-after--pre\">How to parse and visualise these logs?</p><p id=\"4a03\" class=\"graf graf--p graf-after--p\">We’re using <a href=\"https://www.elastic.co/products/logstash\" data-href=\"https://www.elastic.co/products/logstash\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">Logstash</a> to parse logs and <a href=\"https://www.elastic.co/products/kibana\" data-href=\"https://www.elastic.co/products/kibana\" class=\"markup--anchor markup--p-anchor\" rel=\"nofollow noopener\" target=\"_blank\">Kibana</a> to display diagrams. GC-specific patterns are defined as follows:</p><pre id=\"d15f\" class=\"graf graf--pre graf-after--p\">FLOAT %{INT}\\.[0–9]+<br />GCTYPE (GC)|(Full GC)<br />GCREASON [^)]+<br />JVMGCLOG (%{TIMESTAMP_ISO8601:timestamp}: )?%{FLOAT}: (#%{INT}: )?\\[%{GCTYPE:gc_type} (\\(%{GCREASON:gc_reason}\\) )?%{INT:gc_memory_before:int}K-&gt;%{INT:gc_memory_after:int}K\\(%{INT}K\\), %{FLOAT:gc_duration:float} secs\\]</pre><p id=\"c53f\" class=\"graf graf--p graf-after--pre\">and configuration to parse desired entries:</p><pre id=\"666b\" class=\"graf graf--pre graf-after--p\">input {<br />  file {<br />    type =&gt; \"cassandra-gc\"<br />    path =&gt; \"/var/log/cassandra/gc.log\"<br />  }<br />}</pre><pre id=\"a576\" class=\"graf graf--pre graf-after--pre\">filter {<br />  if [type] == \"cassandra-gc\" {<br />    grok {<br />      patterns_dir =&gt; [ \"/etc/logstash/conf.d/patterns\" ]<br />      match =&gt; [ \"message\", \"%{JVMGCLOG}\" ]<br />      remove_field =&gt; [ \"message\" ]<br />    }</pre><pre id=\"9010\" class=\"graf graf--pre graf-after--pre\">    mutate {<br />      add_field =&gt; [ \"program\", \"cassandra-gc\" ]<br />      add_field =&gt; [ \"fqdn\", \"db8.sync.ams.osa\" ]<br />    }</pre><pre id=\"38df\" class=\"graf graf--pre graf-after--pre\">    if [gc_type] == \"Full GC\" {<br />      mutate {<br />        replace =&gt; [ \"gc_type\", \"Full\" ]<br />      }<br />    }<br />  }<br />}</pre><pre id=\"ad81\" class=\"graf graf--pre graf-after--pre\">output {<br />  if [type] in [ \"cassandra-gc\" ] {<br />    redis {<br />      host =&gt; \"logs.sync.ams.osa\"<br />      data_type =&gt; \"list\"<br />      key =&gt; \"logstash\"<br />    }<br />  }<br />}</pre><p id=\"89d1\" class=\"graf graf--p graf-after--pre\">To each log we’re adding “fqdn” field with hostname set to it. The value of this field is set by <em class=\"markup--em markup--p-em\">Puppet</em> in our case. Having “fqdn” will allow us to filter based on specific host or datacenter (f.ex “ams.osa” to get only boxes in Amsterdam).</p><p id=\"57f6\" class=\"graf graf--p graf-after--p\">Having everything in Elasticsearch (passed through Redis) we can easily add dashboards in Kibana:</p><figure id=\"0735\" class=\"graf graf--figure graf-after--p\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*FLSdmh1q0B8iq20CZAvvvA.png\" data-width=\"1024\" data-height=\"310\" data-action=\"zoom\" data-action-value=\"1*FLSdmh1q0B8iq20CZAvvvA.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*FLSdmh1q0B8iq20CZAvvvA.png\" alt=\"image\" /></div></div></figure><figure id=\"cc8e\" class=\"graf graf--figure graf-after--figure\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*iXa4XXu51ANzlKfIC9TlXg.png\" data-width=\"884\" data-height=\"319\" data-action=\"zoom\" data-action-value=\"1*iXa4XXu51ANzlKfIC9TlXg.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*iXa4XXu51ANzlKfIC9TlXg.png\" alt=\"image\" /></div></div></figure><figure id=\"2752\" class=\"graf graf--figure graf-after--figure\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*eOiCcGBeVkWrMUA0exEjHA.png\" data-width=\"880\" data-height=\"320\" data-action=\"zoom\" data-action-value=\"1*eOiCcGBeVkWrMUA0exEjHA.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*eOiCcGBeVkWrMUA0exEjHA.png\" alt=\"image\" /></div></div></figure><figure id=\"9848\" class=\"graf graf--figure graf-after--figure\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*oP34AjE2o_539IESIDC4jA.png\" data-width=\"878\" data-height=\"325\" data-action=\"zoom\" data-action-value=\"1*oP34AjE2o_539IESIDC4jA.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*oP34AjE2o_539IESIDC4jA.png\" alt=\"image\" /></div></div></figure><p id=\"45fe\" class=\"graf graf--p graf-after--figure\">Setup we’ve can be applied to any tool on top of JVM where you want to monitor garbage collector. Logstash can be also helpful if you want to extract other information from Cassandra’s system.log like information about compacting large partitions:</p><pre id=\"f651\" class=\"graf graf--pre graf-after--p\">WARN [CompactionExecutor:77446] 2015–12–07 08:02:40,920 SSTableWriter.java:241 — Compacting large partition sync/entity2:85373422:32904 (105951664 bytes)</pre><p id=\"b1c2\" class=\"graf graf--p graf-after--pre\">Such information is easily parseable and is a great help while deciding if changes in database schema are required:</p><figure id=\"9559\" class=\"graf graf--figure graf-after--p graf--trailing\"><div class=\"aspectRatioPlaceholder is-locked\"><div class=\"aspectRatioPlaceholder-fill\"><img class=\"graf-image\" data-image-id=\"1*1fkSEFVgIiAiTOWxTLhbCg.png\" data-width=\"752\" data-height=\"354\" data-action=\"zoom\" data-action-value=\"1*1fkSEFVgIiAiTOWxTLhbCg.png\" src=\"https://cdn-images-1.medium.com/max/1600/1*1fkSEFVgIiAiTOWxTLhbCg.png\" alt=\"image\" /></div></div></figure></div></div></section><section class=\"section section--body section--last\"><div class=\"section-divider\"><hr class=\"section-divider\" /></div><div class=\"section-content\"><div class=\"section-inner sectionLayout--insetColumn\"><p id=\"aa5d\" class=\"graf graf--p graf--leading\">Using tool like <em class=\"markup--em markup--p-em\">jconsole</em>,<em class=\"markup--em markup--p-em\"> jstat </em>or<em class=\"markup--em markup--p-em\"> jvisualvm</em> is extremely helpful while incidents but to have a bigger picture you need to have a history to detect patterns or make sure everything was fine last night or during last weekend. This is why we’re friends now with Logstash and Kibana. Right away you can say if current incident is caused by GC or you should start looking for problems in other places.</p><p id=\"438c\" class=\"graf graf--p graf-after--p graf--trailing\">Having proper monitoring of garbage collector accompanied with tons of other <a href=\"http://medium.com/@mlowicki/monitoring-cassandra-a7fde5b2de9c\" data-href=\"http://medium.com/@mlowicki/monitoring-cassandra-a7fde5b2de9c\" class=\"markup--anchor markup--p-anchor\" target=\"_blank\">metrics</a> save us lots of time needed to diagnose issues or prove that latest changes in configuration actually make things better.</p></div></div></section>"}}]}},"pageContext":{"alternative_id":9258}}